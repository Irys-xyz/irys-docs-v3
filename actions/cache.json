{
  "lastUpdated": "2025-03-10T00:28:53.039Z",
  "files": [
    {
      "path": "/build/d/downloading",
      "content": " Instantly downloading data from our gateway ;Downloading Data Once data is uploaded, it becomes instantly accessible via our gateway. To download data, make a GET request. URL format https://gateway.irys.xyz/:transactionIdExample https://gateway.irys.xyz/CO9EpX0lekJEfXUOeXncUmMuG8eEp5WJHXl9U9yZUYAIrys is currently in alpha testnet. At mainnet launch, all data uploaded to bundlers will be migrated from testnet to mainnet, with no changes to transaction IDs. "
    },
    {
      "path": "/build/d/features/balance-approvals",
      "content": " Pay for your users uploads using Irys's Balance Approvals ;Balance Approvals Use balance approvals to share balances between multiple addresses. This helps to onboard users without requiring them to own tokens. With balance approvals: You pay for transactions. Users sign transactions. Balance approvals: Are based on the token set when connecting to an Irys node. Both approver and approvee must use the sametoken. Are registered instantly upon upload completion. Are non-transferable. Can be configured to expire automatically.Create an Approval To update an existing approval, create a new approval with the same address (it will overwrite the existing approval). const receipt = await irys.approval.createApproval({amount: irys.utils.toAtomic(1), // Amount in atomic unitsapprovedAddress: \"\",expiresInSeconds: 100, // Expires in 100 seconds. Delete to remove expiration. });Upload Using an Approval const receipt = await irys.upload(\"Hirys World\", { upload: { paidBy: \"\" } }); Combine approvals and tags: const uploadOptions = {upload: {paidBy: \"\",},tags: [{ name: \"Content-Type\", value: \"text/plain\" }], }; const receipt = await irys.upload(dataToUpload, uploadOptions);Revoke an Approval const receipt = await irys.approval.revokeApproval({ approvedAddress: \"\" });Get Balances You're Approved To Use Get approvals from the array of addresses provided: const approvals = await irys.approval.getApprovals({payingAddresses: [\"\"], }); Get the first 100 approvals: const approvals = await irys.approval.getApprovals({}); Return type: {amount: string; // Amount approved in atomic unitspayingAddress: string; // Address of the payer's walletapprovedAddress: string; // Address of the wallet that received the approvalexpiresBy: number; // Timestamp (in milliseconds) when approval expirestimestamp: number; // Timestamp (in milliseconds) when the approval was createdtoken: string; // Approved token } [];Get Approvals You've Created Get approvals for the array of addresses provided: const createdApprovals = irys.approval.getCreatedApprovals({approvedAddresses: [\"\"], }); Get the first 100 approvals you've created: const createdApprovals = irys.approval.getCreatedApprovals({}); Return type: {amount: string; // Amount approved in atomic unitspayingAddress: string; // Address of the payer's walletapprovedAddress: string; // Address of the wallet that received the approvalexpiresBy: number; // Timestamp (in milliseconds) when approval expirestimestamp: number; // Timestamp (in milliseconds) when the approval was createdtoken: string; // Approved token } [];Get Balance Approvals via HTTP You can also request balance approvals via HTTP: Testnet: https://testnet.irys.xyz/account/approval?payingAddress=&token=&approvedAddress= `"
    },
    {
      "path": "/build/d/features/ipfs-cid",
      "content": " Use IPFS CIDs when addressing data on Irys. ;IPFS Content IDs In addition to using Irys transaction IDs, you can also use IPFS Content IDs (CIDs) when addressing data on Irys.Irys does not currently verify that CIDs match their uploaded data. This will be added in a future release. Content IDs vs transaction IDs IPFS and Irys take a different approach to identifying data, IPFS uses Content Identifiers (CIDs) and Irys uses transaction IDs. IPFS Content Identifiers (CIDs) are generated by hashing the content being uploaded. The same data uploaded twice will generate the same CID. Irys transaction IDs are generated by hashing the content + metadata being uploaded. All uploads have a unique transaction ID.Uploading with a CID To upload data to Irys using a CID, embed it as the value of the IPFS-CID tag when uploading data.Use a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.; const generateCID = async (content) => {return await IPFS.of(content); }; const uploadToIrysWithCID = async () => {const irys = await getIrysUploader();const dataToUpload = \"Irys + IPFS Content ID\";const contentID = await generateCID(dataToUpload);console.log(ContentID=${contentID});const tags = [{ name: \"Content-Type\", value: \"text/html\" },{ name: \"IPFS-CID\", value: contentID },];const receipt = await irys.upload(dataToUpload, { tags: tags });// You can download using either the Irys transaction ID or IPFS Content IDconsole.log(Transaction ID URL https://gateway.irys.xyz/${receipt.id});console.log(Content ID URL https://gateway.irys.xyz/ipfs/${contentID}); };This code example generates a CID using the ipfs-only-hash package which uses the SHA-256 algorithm by default. IPFSalso allows CIDs to be generated using SHA3 and Blake2, all of which are supported when uploading to Irys. Downloading with a CID To download data tagged with a CID, request it from the Irys gateway using a URL in the format https://gateway.irys.xyz/ipfs/:contentID.If the same CID is assigned to more than one transaction, the Irys gateway will always return the one with theearliest timestamp.const fetchData = async (ipfsCID) => {const url = https://gateway.irys.xyz/ipfs/${ipfsCID};console.log(URL: ${url});const response = await fetch(url);const data = await response.text();console.log(DATA: ${data}); };Migrating data from IPFS to Irys You can migrate data from IPFS to Irys by first downloading the data from an IPFS gateway and then uploading it to Irys. Users can choose to tag the uploads with the original IPFS CID and continue to retrieve data using the CID, or switch to using Irys transaction IDs. This code example shows how to: Download data from an IPFS gateway Determine the data's content type (for example: image/png) Re-upload the data to Irys while tagging it with the existing content typePrior to uploading, users must fund an Irys node. Most users will choose to [up-frontfund](/build/d/sdk/payment/fund#upfront-funding) where they pre-fund an Irys node with sufficient tokens to cover all databeing migrated. Users can also choose to lazy-fund the uploads where you fund eachseparate upload.; ; const uploadToIrysWithCID = async (dataToUpload, contentType, contentID) => {const irys = await getIrysUploader();const tags = [{ name: \"Content-Type\", value: contentType },{ name: \"IPFS-CID\", value: contentID },];const receipt = await irys.upload(dataToUpload, { tags: tags });console.log(Direct URL: https://gateway.irys.xyz/${receipt.id});console.log(Content ID URL: https://gateway.irys.xyz/ipfs/${contentID}); }; const downloadAndDetermineContentType = async (ipfsCID) => {try {const ipfsURL = https://ipfs.io/ipfs/${ipfsCID};const response = await fetch(ipfsURL);const arrayBuffer = await response.arrayBuffer();const buffer = Buffer.from(arrayBuffer);const contentType = await fileTypeFromBuffer(buffer);if (contentType) {console.log(Content Type: ${contentType.mime});await uploadToIrysWithCID(buffer, contentType.mime, ipfsCID);} else {console.error(\"Unable to determine content type\");}} catch (error) {console.error(\"Error:\", error);} }; const ipfsCID = \"QmUgL4YbnW9vMWZXLdAFzgxJwxpxJapZRLpjoT2ubU5WmF\"; downloadAndDetermineContentType(ipfsCID); `"
    },
    {
      "path": "/build/d/features/manual-tx",
      "content": " Manually creating, signing and uploading a transaction. ;Manually Creating a Transaction In addition to uploading using the SDK functions irys.upload(),irys.uploadFile(), and irys.uploadFolder(), you can also manually create, sign, and upload a transaction in separate steps.Workflow const tx = irys.createTransaction() await tx.sign() await tx.upload() After calling tx.sign(), you can access the transaction ID via tx.id, this facilitates use cases where you need access to the ID before uploading the full transaction.You must call tx.sign() before using the value of tx.id. Creating, Signing, Uploading Basic workflow.Use a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const createSignUpload = async () => {// Get a reference to a pre-configured Irys objectconst irys = await getIrysUploader();// Create the transactionconst tx = irys.createTransaction(\"Hirys World!\", { tags: [{ name: \"Content-Type\", value: \"text/plain\" }] });// Sign the transactionawait tx.sign(); // ID is now setconsole.log(Tx created and signed, ID=${tx.id});// Upload the transactionconst receipt = await tx.upload();console.log(Tx uploaded. https://gateway.irys.xyz/${receipt.id}); };Serializing a Transaction Serialize a transaction and recreate it later. const serializationUpload = async () => {// Get a reference to a pre-configured Irys objectconst irys = await getIrysUploader();// Create the transactionconst tx1 = irys.createTransaction(\"Hirys World!\", { tags: [{ name: \"Content-Type\", value: \"text/plain\" }] });// Note: You can sign before or after serializingawait tx1.sign(); // ID is now setconsole.log(Tx created and signed, ID=${tx1.id});// Serialize the transactionconst txSerialized = tx1.getRaw();// Recreate the transaction from the serialized versionconst tx2 = irys.transaction.fromRaw(txSerialized);// ID is the same as beforeconsole.log(Tx re-created from serialized, ID=${tx2.id});// Upload the txconst receipt = await tx2.upload();console.log(Tx uploaded. https://gateway.irys.xyz/${receipt.id}); };Deterministic ID Use a deterministic ID in cases where you need access to a transaction ID before uploading, but can't or don't want to store a reference to the transaction object. First, generate an anchor and use that to create a transaction with your data. Then, sign the transaction and you can access the ID. Finally, you can recreate the transaction using the same anchor and data and your ID will be the same. const deterministicIDUpload = async () => {// Get a reference to a pre-configured Irys objectconst irys = await getIrysUploader();// Generate 32 bytes through Buffer.from(anchor)const anchor = randomBytes(16).toString(\"hex\");const tx1 = irys.createTransaction(\"Hirys Irys!\", {tags: [{ name: \"content-type\", value: \"text/plain\" }],anchor,});await tx1.sign();console.log(Tx1 ID ${tx1.id}); // ID is now setconst tx2 = irys.createTransaction(\"Hirys Irys!\", {tags: [{ name: \"content-type\", value: \"text/plain\" }],anchor,});await tx2.sign();console.log(Tx2 ID ${tx2.id}); // ID is the sameconst receipt = await tx2.upload();console.log(Tx uploaded. https://gateway.irys.xyz/${receipt.id}); }; `"
    },
    {
      "path": "/build/d/features/mutability",
      "content": " Mutable references enable the creation of a single, static URL that is linked to a sequential series of transactions. ;Mutability Data on Irys is immutable. However, you can simulate mutability on using mutable references. With mutable references you create a single, static URL that is linked to a sequential series of transactions. You can add a new transaction to the series at any time, and the URL will always resolve to the most recent transaction in the chain.To create a mutable reference: Upload a base transaction to Irys and reference it using a URL in the following format https://gateway.irys.xyz/mutable/:txIdUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irysUploader = await getIrysUploader(); const receiptOne = await irysUploader.upload(\"First TX\"); console.log(TX 1 uploaded https://gateway.irys.xyz/mutable/${receiptOne.id}); Upload an addition to the series as a new transaction, and add a tag named Root-TX with the value of the original transaction ID. const tags = [{ name: \"Root-TX\", value: receiptOne.id }]; const receiptTwo = await irysUploader.upload(\"Second TX\", { tags: tags }); console.log(TX 2 uploaded https://gateway.irys.xyz/mutable/${receiptOne.id}); The original URL (https://gateway.irys.xyz/mutable/:txId) now resolves to the second transaction in the chain.When building a transaction chain, additions must be made using the same wallet that created the original transaction.This prevents unauthorized actors from maliciously modifying someone else’s transaction chain. Granularity Mutable references are based on Irys’s millisecond-accurate timestamps. You can publish multiple sequential updates to a given transaction and be confident the transaction served by the /mutable/ endpoint will always be the most recent chronological one.Versions While the https://gateway.irys.xyz/mutable/:txId endpoint will always resolve to the most recent transaction in a chain, it is possible to directly access any transaction in a chain using the transaction’s ID and a URL in the format https://gateway.irys.xyz/:id You can query a version chain using GraphQL: query getChain {transactions(tags: [{name: \"Root-TX\"values: [\"WF--VR1ZERvABYy1aNYD3QJ0OAVDSUF8dTlg6zFKveQ\"]}]owners: [\"0x591b5ce7ca10a55a9b5d1516ef89693d5b3586b8\"]order: ASC) {edges {node {idtimestamp}}} }Use-Cases Irys’s mutable references open up new opportunities for builders, including: Gaming NFTs: Metadata changes based on in-game actions Dynamic NFTs: Images change based on onchain activity Software distribution: The latest version is always available via the same link Content publishing / social media: Content can be updated at any time and users will always have the most recent version Website hosting / dApp front-ends: Websites can be updated at any time without changing the main URL"
    },
    {
      "path": "/build/d/features/onchain-folders",
      "content": " Onchain folders create logical groupings of files. ;Onchain Folders Onchain folders are powerful way to organize transactions on Irys. Use them to reference onchain data by logical names instead of transaction IDs. Why Use Onchain Folders? Logical Grouping: Create organized and readable structures for onchain data. Human-Readable Referencing: Replace transaction IDs with logical names, improving accessibility. Cross-Ownership Grouping: Include any transactions on Irys, even if they weren’t created by you. Flexibility: Add new files to existing folders at any time.How The Irys Gateway Resolves Onchain Folders Each onchain folder is uniquely identifiable by a manifest ID. To download transactions in an onchain folder, request them from the Irys gateway using a URL formatted as: https://gateway.irys.xyz/:manifestId/:pathName The gateway then: Looks up the manifest by ID. Looks in the manifest to see if the path exists. Returns the transaction associated with the path if found. Returns 404 if not found. For example, if you have a manifest with ID 8eNpkShMwdbiNBtGuVGBKp8feDZCa21VppX2eDi3eLME containing the following: | Tx ID| Path Name| | ---------------------------------------------- | ---------- | | DTMcqFqwaDukaYxs7iK2fa6CuMtyi7sN93rBGSAa13Ug | foo1.png | | 5TQU2ETHGRPjJKPoeQkkgMB6zRpK8ptheWF8jdkbtJHR | foo2.png | | 8nond6kkdYS14QjA5tZNCRDQQrgVNd7gdhx3L4XRJD1b | foo3.png | https://gateway.irys.xyz/8eNpkShMwdbiNBtGuVGBKp8feDZCa21VppX2eDi3eLME/foo1.pngCreating Onchain FoldersAutomatically When you upload groups of files using the Irys SDK's uploadFolder() function or the CLI's upload-dir command, an onchain folder for you is automatically created for you. The return value contains the manifest ID, which can be combined with the original file names as above.Manually To manually create an onchain folder: Create a JavaScript Map object where each entry maps a unique transaction ID to a unique path. (Paths are arbitrary; you can use anything that conforms to valid URL syntax.) Create a Manifest object by passing the Map object to irys.uploader.generateFolder(). Upload the Manifest object to Irys. const createOnchainFolder = async () => {const irysUploader = await getIrysUploader();// You can map ANY logical name to ANY transaction IDconst map = new Map();map.set(\"image-1.png\", \"DTMcqFqwaDukaYxs7iK2fa6CuMtyi7sN93rBGSAa13Ug\");map.set(\"image-2.png\", \"5TQU2ETHGRPjJKPoeQkkgMB6zRpK8ptheWF8jdkbtJHR\");map.set(\"image-3.png\", \"8nond6kkdYS14QjA5tZNCRDQQrgVNd7gdhx3L4XRJD1b\");const manifest = await irysUploader.uploader.generateFolder({ items: map });console.log({ manifest });const tags = [{ name: \"Type\", value: \"manifest\" },{ name: \"Content-Type\", value: \"application/x.irys-manifest+json\" },];const receipt = await irysUploader.upload(JSON.stringify(manifest), { tags });console.log(Manifest uploaded to https://gateway.irys.xyz/${receipt.id});console.log(File 1 available at https://gateway.irys.xyz/${receipt.id}/image-1.png);console.log(File 2 available at https://gateway.irys.xyz/${receipt.id}/image-2.png);console.log(File 3 available at https://gateway.irys.xyz/${receipt.id}/image-3.png); };Mutable Onchain Folders Mutable onchain folders let you add new files to an existing folder after it’s created. By using a single, static URL that always points to the most recent version, you can expand an NFT collection, add updated documents, or manage evolving datasets without needing to change the original reference. This approach ensures consistency while allowing dynamic updates over time, with the security that only the original creator can modify the folder's contents.How to Create Mutable Onchain Folders Upload the Initial Folder: Use the SDK or CLI to upload your initial set of files. This will create a base manifest ID that uniquely identifies the folder. Reference Files Using a Mutable URL: Reference files in this folder using a URL formatted as https://gateway.irys.xyz/mutable/:manifestId/:fileName. This URL will always resolve to the most recent version of the folder. Upload New Files: When you need to add new files, upload them individually using the SDK or CLI. Create a Onchain Folder: Manually create a new onchain folder that includes both the original files and any new files as outlined above. Tag the New Manifest: Upload the new onchain folder to Irys, tagging it with Root-TX equal to the original manifest ID. This links the new onchain folder to the original folder; the \"mutable\" URL remains consistent. Access the Updated Folder: The URL https://gateway.irys.xyz/mutable/:manifestId/:fileName will now point to the latest version of the folder, including all newly added files. ; ; import \"dotenv/config\"; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Ethereum).withWallet(process.env.PRIVATE_KEY);return irysUploader; }; const downloadOriginalManifest = async (originalManifestId: string) => {try {const response = await fetch(https://gateway.irys.xyz/${originalManifestId});if (!response.ok) throw new Error(\"Failed to fetch original manifest\");return response.json();} catch (error) {console.error(\"Error downloading original manifest\", error);throw error;} }; const appendToManifest = (originalManifest: any, newFiles: Map)=> {newFiles.forEach((txId, fileName) => {originalManifest.paths[fileName] = { id: txId };});return originalManifest; }; const uploadManifest = async (manifest: any, originalManifestId: string): Promise => {const irysUploader = await getIrysUploader();const manifestTags = [{ name: \"Type\", value: \"manifest\" },{ name: \"Content-Type\", value: \"application/x.irys-manifest+json\" },{ name: \"Root-TX\", value: originalManifestId },];try {const manifestResponse = await irysUploader.upload(JSON.stringify(manifest), { tags: manifestTags });console.log(Manifest uploaded ==> https://gateway.irys.xyz/mutable/${originalManifestId});} catch (e) {console.error(\"Error uploading manifest\", e);} }; const main = async () => {try {// Your original manifest IDconst originalManifestId = \"8eNpkShMwdbiNBtGuVGBKp8feDZCa21VppX2eDi3eLME\";// Step 1: Download the original manifestconst originalManifest = await downloadOriginalManifest(originalManifestId);// Step 2: Prepare new files to add to the manifestconst newFiles = new Map();newFiles.set(\"new-1.png\", \"4pTiwGwur38s4vyVD8EERxDYgAGDM8kyzEh9c5QPF9Zw\");newFiles.set(\"new-2.png\", \"BieiKJE1Nh6ydCYqxmDjHFGzuG7enRr6NYmKisqSwUQo\");// Step 3: Append new files to the manifestconst updatedManifest = appendToManifest(originalManifest, newFiles);// Step 4: Upload the updated manifestawait uploadManifest(updatedManifest, originalManifestId);} catch (e) {console.error(\"Error in main execution\", e);} }; main(); `"
    },
    {
      "path": "/build/d/features/receipts",
      "content": " Signed receipts provide proof of time ;Receipts Receipts give you cryptographic proof of the exact time, accurate to the millisecond, that a transaction was posted.Receipts & Timestamps When you upload data to Irys, it is stamped with a millisecond-accurate timestamp before being stored onchain. Blockchains rely on timestamps to sequence the order of transactions and blocks. Transaction sequencing plays a critical role in blockchain security as it ensures that all transactions are recorded in the correct order, and that order is never changed. Receipts provide cryptographic proof of a timestamp.Ordering & Streaming Ordering and streaming applications process and deliver data in real-time. They're commonly used for messaging, event processing, and data integration. They transfer high data volumes between independent applications while maintaining high performance and scalability. Popular examples include Apache Kafka and RabbitMQ.Why Use Signed Receipts? Cryptographically signed receipts open up new development options for builders. For example: Sequential ordering of posts, likes and comments for a decentralized social protocol. Sequential ordering of data generated by a group messaging protocol. Automatically adjudicating music copyright claims. Preserving history, ensuring it's not manipulated over time. Preserving scientific research using Irys's pay-once, store-forever model.Receipt Permanence Upon posting a transaction to Irys, a receipt is immediately returned to the user. Irys maintains an internal registry of all receipts, which can be queried whenever a receipt is needed. These receipts are stored in a centralized fashion, which may be sufficient for users comfortable with the trust assumptions of centralized services. You can also opt to permanently store your receipt on Irys by uploading it using our SDK or CLI.Receipt format Receipts are a JSON object with the following format: {id: '1Txlbl5NgEqUbIkDnnunHC0gFx0n8_Y92zAsoX54kI8',timestamp: 1676891681110,version: '1.0.0',public: '...',signature: '...',deadlineHeight: ...,block: ...,validatorSignatures: [], } | Field| Description| | ------------------- | ---------------------------------------------------------------------- | | ID| Transaction ID (used to download the data)| | timestamp| Timestamp (UNIX milliseconds) of when the transaction was created| | version| The version of this JSON file, currently 1.0.0| | public| Public key of the bundler node used| | signature| A signed deep hash of the JSON receipt| | deadlineHeight| The block number by which the transaction must be finalized| | block| Deprecated| | validatorSignatures | Deprecated|Verifying Receipts You may need to verify a receipt at some point after it was issued. For example, if your application’s security depends on the order of transactions, you can then verify every receipt to ensure its order has not been tampered with. The receipt contains a signature field, which is generated by creating a deep hash of information from the receipt, including transaction ID and timestamp. The receipt is then signed it by Irys. Using the Irys SDK you can verify the signature using the using the same values from the receipt along with the supplied public key.Timestamp Generation Irys records the precise time of each transaction with a UNIX timestamp in milliseconds. This timestamp is generated by the node that first receives and verifies the transaction."
    },
    {
      "path": "/build/d/features/supported-tokens",
      "content": " Pay for your upload with most popular tokens.Supported Tokens Iyrs supports most popular tokens for paying for uploads.Testnet On our testnet, you can pay for uploads in any of these tokens: | Token / Blockchain | Token | Parameter Value | Node Support| Browser Support| | ------------------ | ----- | --------------- | -------------- | ----------------- | | Aptos| APT| aptos| yes| yes| | Algorand| ALGO| algorand| yes| no| | Arbitrum| ETH| arbitrum| yes| yes| | Avalanche C-Chain| AVAX| avalanche| yes| yes| | Berachain| BERA| bera| yes| yes| | Binance Coin| BNB| bnb| yes| yes| | Boba| BOBA| boba| yes| yes| | Boba-eth| ETH| boba-eth| yes| yes| | Chainlink| LINK| chainlink| yes| yes| | Eclipse-eth| ETH| eclipse-eth| yes| yes| | Ethereum| ETH| ethereum| yes| yes| | Base Ethereum| ETH| base-eth| yes| yes| | Linea Ethereum| ETH| linea-eth| yes| yes| | Scroll Ethereum| ETH| scroll-eth| yes| yes| | Fantom| FTM| fantom| yes| yes| | IoTeX| IoTeX | iotex| yes| yes| | Near| NEAR| near| yes| yes| | Polygon| MATIC | matic| yes| yes| | Solana| SOL| solana| yes| yes| | USDC (on Ethereum) | USDC| usdc-eth| yes| yes| | USDC (on Polygon)| USDC| usdc-polygon| yes| yes| | USDC (on Solana)| USDC| usdc-solana| yes| yes|Devnet On devnet, uploads are paid for with free faucet tokens. Data is deleted after ~60 days. | Token / Blockchain| Token | Parameter Value | Irys Support | WebIrys Support | | -----------------------------| ----- | --------------- | -------------- | ----------------- | | Aptos| APT| aptos| yes| yes| | Algorand| ALGO| algorand| yes| no| | Arbitrum| ETH| arbitrum| yes| yes| | Avalanche C-Chain| AVAX| avalanche| yes| yes| | Berachain| BERA| bera| yes| yes| | Binance Coin| BNB| bnb| yes| yes| | Chainlink| LINK| chainlink| yes| yes| | Ethereum (Sepolia)| ETH| ethereum| yes| yes| | Base Ethereum (Sepolia)| ETH| base-eth| yes| yes| | Linea Ethereum (Sepolia)| ETH| linea-eth| yes| yes| | Scroll Ethereum (Sepolia)| ETH| scroll-eth| yes| yes| | IoTeX| IoTeX | iotex| yes| yes| | Near| NEAR| near| yes| yes| | Polygon (Amoy)| AMOY| matic| yes| yes| | Solana| SOL| solana| yes| yes| | USDC (on Ethereum)| USDC| usdc-eth| yes| yes| | USDC (on Polygon)| USDC| usdc-polygon| yes| yes| | USDC (on Solana)| USDC| usdc-solana| yes| yes| | Eclipse-eth (eclipse faucet) | ETH| eclipse-eth| yes| yes|Connecting to Irys The Irys SDK reduces dependency bloat by providing dedicated packages for each token. Your import statements and connection code will differ depending on the token used for payment. The following code is for using ethereum only, we also have examples covering all of the tokens we support for payment. ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Ethereum).withWallet(process.env.PRIVATE_KEY);return irysUploader; }; `"
    },
    {
      "path": "/build/d/features/tags",
      "content": " Tagging uploads with custom metadata.Metadata Tagging Irys supports attaching metadata tags to each transaction. Tags can be used to: Categorize transactions, making it easier to search for and retrieve relevant information Create mutable data Inform web browsers how to render files (e.g. Content-Type = image/png)Querying Tags are indexed by gateways and are queryable using GraphQL.Content-Type Irys automatically infers and sets the appropriate Content-Type tag based on the file extension when uploading files and folders. You can also manually set the Content-Type tag, doing so will override the default behavior and apply the value you provide. // Your file const fileToUpload = \"./myImage.png\"; // Add a custom Content-Type tag const tags = [{ name: \"Content-Type\", value: \"image/png\" }]; try {const response = await irys.uploadFile(fileToUpload, { tags: tags });console.log(File uploaded ==> https://gateway.irys.xyz/${response.id}); } catch (e) {console.log(\"Error uploading file \", e); } You can also add tags via the CLI's -t option, followed by a series of name / value pairs irys upload myImage.png \\-n testnet \\-t ethereum \\-w bf20......c9885307 \\--tags tagName1 tagValue1 tagName2 tagValue2 \\--provider-url https://rpc.sepolia.devAdditional Uses You can add up to 20 tags to each transaction, enabling the construction of semi-relational models within your data. A popular practice involves creating an application-id tag, this tag helps segregate your uploads from others. // Your file const fileToUpload = \"./myNFT.png\"; const tags = [{ name: \"application-id\", value: \"NFTs To The Moon\" }]; try {const response = await irys.uploadFile(fileToUpload, { tags: tags });console.log(File uploaded ==> https://gateway.irys.xyz/${response.id}); } catch (e) {console.log(\"Error uploading file \", e); } `"
    },
    {
      "path": "/build/d/features/txids",
      "content": " Transaction IDs uniquely identify transaction on Irys ;Transaction IDs Transaction IDs uniquely identify transactions on Irys. When you upload data via a bundler, you receive a receipt containing the transaction ID, this serves as a reference for retrieving or verifying that data.Encoding Transaction IDs are base58 encoded.Base58 is a binary-to-text encoding scheme that is commonly used in Bitcoin and Solana. It uses an alphabet of 58 characters, which is the same as the Base64 encoding scheme, but omits the characters 0, O, I, and l to avoid confusion between similar-looking letters and numbers. Downloading Data with Transaction IDs Use your unique transaction ID to download data from our gateway using a URL in the format https://gateway.irys.xyz/:transactionId Example https://gateway.irys.xyz/CO9EpX0lekJEfXUOeXncUmMuG8eEp5WJHXl9U9yZUYA"
    },
    {
      "path": "/build/d/graphql",
      "content": " Search Irys transaction metadata using GraphQL. ;Querying With GraphQL You can query Irys transaction metadata using GraphQL.GraphQL Clients You can query using an HTTP library like fetch or axios, or use specialized clients like Apollo Client or urql.Endpoint https://uploader.irys.xyz/graphqlAnatomy of a Query A GraphQL query is made up of: Query Arguments: Specify search parameters, limit the number of results returned, or enable pagination. Results Fields: Fields that define the data you want to retrieve. Query Arguments Any of the following query arguments can be used as search parameters: | Field| Description| | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | ids| An array of transaction IDs passed as strings. Values are ORed together, matching results will include transactions that have any of the supplied IDs.| | owner | The address used when posting the transaction. Can be a native address from any of the chains supported by Irys. Note in results fields, this is referred to as address. | | token | The token used to pay for the transaction.| | tags| An array of tag name / value pairs passed as JSON objects.|Results Fields When building a query, any of the following values be included in your results: | Field | Description | |---|---| | id | The transaction ID. | | address | The address used when posting the transaction. Can be a native address from any of the chains supported by Irys. Note in query arguements, this is referred to as owner. | | token | The token used to pay for the transaction. | | receipt { &nbsp;&nbsp;deadlineHeight &nbsp;&nbsp;signature&nbsp;&nbsp;version } | An optional receipt, only exists if a user requested one at upload. deadlineHeight: The block number by which the transaction must be finalized. signature: A signed deep hash of the JSON receipt. | | tags {&nbsp;&nbsp;name&nbsp;&nbsp;value} | An array of tags supplied as name / value pairs. Exists if the user added them at upload. | |timestamp | The timestamp, accurate to the millisecond of when the transaction was posted. This value is the same as the receipt timestamp. |GraphQL Sandbox Clicking on the endpoint URL above will take you to the GraphQL Sandbox used for building and testing queries. Press Control+Space at any time to see an interactive popup window of either query arguments or results fields. Sample Queries Queries return transaction metadata. To then retrieve data, use the returned transaction ID and download the data from the Irys gateway using a URL formed as follows: https://gateway.irys.xyz/:transactionId.Transaction IDs Search by transaction IDs. query getByIds {transactions(ids: [\"--52WQHJIJodrni8pkl1Vxt9MFGoXZAm8SC7ex6C1o\", \"--52THRWpXRJzGcNXmtQ2DSP37d1e1VQ4YmvbY5ZXo\"]) {edges {node {idtags {namevalue}}}} }Timestamps Search by timestamps: query getByTimestamp {transactions(timestamp: { from: 1688144401000, to: 1688317201000 }) {edges {node {id}}} }Irys timestamps are accurate to the millisecond, so you need to provide a timestamp in millisecond format when querying. You canconvert from human-readable time to UNIX timestamp using websites like Epoch101, be sureto convert in millisecond format, not second. Owners Search for transactions matching the wallet address used when posting the transaction: query getByOwner {transactions(owners: [\"0xBcb812C6e26F4F0F78Bd7B6222461FF24F2942AE\", \"0xaC568a981B1370B2e1bAA8cE30BD5AC9E28C572D\"]) {edges {node {idaddress}}} }Tags Search for transactions matching tag name / value pairs: query getAllPNGs {transactions(tags: [{ name: \"Content-Type\", values: [\"image/png\"] }]) {edges {node {idaddress}}} } Search for transactions matching the tag with name Content-Type and the values of image/png OR image/jpg: query getTagsWithOR {transactions(tags: [{ name: \"Content-Type\", values: [\"image/png\", \"image/jpg\"] }]) {edges {node {tags {namevalue}}}} } Search for transactions matching the tag with name Content-Type and the values of image/png AND image/jpg: query getTagsWithAnd {transactions(tags: [{ name: \"Content-Type\", values: [\"image/jpg\"] }, { name: \"Content-Type\", values: [\"image/png\"] }]) {edges {node {tags {namevalue}}}} }Limiting Results Limit the number of results returned by including the limit parameter: query getAllPNGs {transactions(limit: 10, tags: [{ name: \"Content-Type\", values: [\"image/png\"] }]) {edges {node {idaddress}}} }Pagination You can request a maximum of 100 results returned from each query, to obtain additional results use pagination. When using pagination you: Retrieve the cursor field, this acts like a bookmark in the search results you can then return to. Use saved cursor value to obtain subsequent search results. The following query returns 10 transactions tagged image/png occurring after the cursor with value: LS02d1NsM3R6aUprd3dKUzVjN1FXaWg5aUxsbXh5dVJJbGlydHJtNlpPbw. To then obtain the next 10 transactions, use the final cursor value returned from this query as the value of the after parameter in the following query. query getPNGs {transactions(limit: 10tags: [{ name: \"Content-Type\", values: [\"image/png\"] }]after: \"LS02d1NsM3R6aUprd3dKUzVjN1FXaWg5aUxsbXh5dVJJbGlydHJtNlpPbw\") {edges {node {id}cursor}} }Sorting You can sort results by timestamp in either ascending or descending order using the order field. query getAllByOwnerAsc {transactions(owners: [\"0xBcb812C6e26F4F0F78Bd7B6222461FF24F2942AE\"], order: ASC) {edges {node {idaddress}}} } query getAllByOwnerDesc {transactions(owners: [\"0xBcb812C6e26F4F0F78Bd7B6222461FF24F2942AE\"], order: DESC) {edges {node {idaddress}}} } `"
    },
    {
      "path": "/build/d/guides/ai-prompts",
      "content": " Store AI prompts and results on Irys to create a permanent, verifiable audit trail. ;Storing AI Prompts on Irys Permanently storing AI prompts and their results is crucial for creating a reliable audit trail. Irys enables this through permanent-onchain storage and signed receipts containing millisecond-accurate timestamps. This guarantees that each stored prompt is verifiable and immutable. This is essential for: Intellectual Property (IP) Protection: Having a precise record of the input and output can help resolve disputes over IP rights, proving that the content generated was based on specific inputs used against a specific model. Model Evolution and Accountability: AI models are continuously updated and retrained, meaning their outputs can change over time (even when given the same prompt). By storing prompts along with metadata, you can trace back the specific conditions under which an AI output was generated. Compliance and Transparency: Regulatory requirements around AI are evolving, and organizations may soon need to demonstrate how and why specific AI-generated content was created.There is currently no universally accepted standard for representing AI prompts; this guide is based on best practices outlined in OpenAI's documentation. Key Elements to Store To store AI prompts, the following elements should be captured: Prompt Text: The actual text of the prompt given to the AI model. Timestamp: The date and time when the prompt was executed. Model Used: The AI model used (e.g., GPT-4, DALL-E 2). Result: The output generated by the AI, or a hash of the output. Hashing Algorithm: If storing a hash of the result, indicate the algorithm used (e.g., SHA-256). In certain cases, the following will be needed too: Parameters: Parameters such as temperature, maxtokens, and stopsequences. Custom Metadata: Additional metadata that might be relevant, such as purpose, user ID, or application context. This can be represented as a JSON object: {\"prompt_text\": \"Translate this text from Esperanto to Toki Pona.\",\"created_at\": \"2024-08-29T15:30:00Z\",\"model\": \"gpt-4\",\"temperature\": 0.7,\"max_tokens\": 150,\"stop_sequences\": [\"\\n\"],\"metadata\": {\"purpose\": \"Translation\",\"user_id\": \"12345\"},\"result\": {\"type\": \"text\",\"output\": \"kama ante e toki pi jan Esperanto tawa toki pona.\",\"hash\": \"9a6e38d09ca3e6a8f2f4d1d6234c1a762c3e8a9d\",\"hash_algo\": \"SHA-256\"} }Storing Results or Hashes It's not always possible to store the full output generated by the AI prompt. For larger outputs, such as images or videos, storing a hash of the result is more efficient.Hashing provides a lightweight way to verify the output. A hash is a fixed-length string of characters generated from data of any size, used to verify the integrity of that data by ensuring it hasn't been altered.{\"prompt_text\": \"Generate an image of the coolest mascot in the universe.\",\"created_at\": \"2024-08-29T15:30:00Z\",\"model\": \"dall-e-2\",\"temperature\": 0.8,\"max_tokens\": 0,\"stop_sequences\": [],\"metadata\": {\"purpose\": \"Image generation\",\"user_id\": \"12345\"},\"result\": {\"type\": \"image\",\"url\": \"https://gateway.irys.xyz/sprite.png\",\"hash\": \"8c14d8a15f5e7a6d1a9a23387cd5eebc1d2c9e8f\",\"hash_algo\": \"SHA-256\"} }Uploading the JSON Object to Irys You can store the JSON object containing the prompt using the Irys CLI: irys upload myPrompt.json \\-n testnet \\-t ethereum \\-w 6dd5e....54a120201cb6a \\--tags Content-Type application/json \\--provider-url https://sepolia.base.org Or SDK:Use a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const uploadMetadata = async () => {const irys = await getIrysUploader();const fileToUpload = \"./myPrompt.json\";const tags = [{ name: \"Content-Type\", value: \"application/json\" }];try {const response = await irys.uploadFile(fileToUpload, { tags: tags });console.log(File uploaded ==> https://gateway.irys.xyz/${response.id});} catch (e) {console.log(\"Error uploading file \", e);} }; Once your prompt is stored onchain with Irys, you have'll have a permanent record of what was executed and when."
    },
    {
      "path": "/build/d/guides/depin-data",
      "content": " Store DePIN data on Irys for secure, permanent, and verifiable onchain storage. ;Storing DePIN Data on Irys DePIN networks need a reliable data layer they can trust. Imagine a network of nodes signing and reporting data onchain and a smart contract that reads this data to mint rewards. This setup only works if the DePIN protocol can easily verify that miners are storing the data they claim to store and that the data hasn’t been tampered with after being uploaded. Additionally, DePIN networks need to chronologically order data so they can process it in the order it was posted. Irys makes this possible with permanent onchain data storage and upload receipts with millisecond-accurate timestamps. Protocols can verify data is stored by miners, ensure it remains unaltered, and sequence it. Data on Irys can be accessed by protocols on any blockchain.Example This guide includes example code showing how to store DePIN messages on Irys, how to tag and query those messages, and how to order them chronologically.Data messages for DePIN networks vary, but the core principles of secure storage, retrieval, and verification remain consistent across different use cases. Device Data Example data for a weather sensor. {\"deviceid\": \"foodevice_001\",\"timestamp\": \"2024-08-29T12:34:56Z\",\"data\": {\"temperature\": 22.5,\"humidity\": 60,\"battery_level\": 85,\"location\": {\"latitude\": 37.7749,\"longitude\": -122.4194}},\"signature\": \"a4f8a2e8e7c4d2a7c3e1f9b6d8e2f1a0c5b7e6a3c4d1f7b8e2a6c1d3e7f8b9c2\" } You can upload your DePIN data to Irys using the Irys CLI: irys upload depin_data.json \\-n testnet \\-t ethereum \\-w 6dd5e....54a120201cb6a \\--tags Content-Type application/json \\ Or through the Irys SDK:Use a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const uploadDePINData = async () => {const irys = await getIrysUploader();const fileToUpload = \"./depin_data.json\";const tags = [{ name: \"Content-Type\", value: \"application/json\" }];try {const response = await irys.uploadFile(fileToUpload, { tags: tags });console.log(File uploaded ==> https://gateway.irys.xyz/${response.id});} catch (e) {console.log(\"Error uploading file \", e);} };Using Tags Irys supports adding metadata tags to each upload, allowing you to categorize data and make it easily searchable. For DePIN networks, tags like device-id, data-type, location, and application-id can be attached to each upload. This makes it simple to filter data by criteria important to your network.Example Tags Here’s how you might tag a data upload: device-id: \"foodevice001\" data-type: \"temperature\" location: \"San Francisco, CA\" application-id: \"DePIN Network Alpha\" const uploadDePINData = async () => {const irys = await getIrysUploader();const fileToUpload = \"./depin_data.json\";const tags = [{ name: \"Content-Type\", value: \"application/json\" },{ name: \"device-id\", value: \"foodevice001\" },{ name: \"data-type\", value: \"temperature\" },{ name: \"location\", value: \"San Francisco, CA\" },{ name: \"application-id\", value: \"DePIN Network Alpha\" }];try {const response = await irys.uploadFile(fileToUpload, { tags: tags });console.log(File uploaded ==> https://gateway.irys.xyz/${response.id});} catch (e) {console.log(\"Error uploading file \", e);} };Querying To query data stored on Irys, you can use GraphQL to search for specific tags and order the results by timestamp: query getDeviceTemperatureData {transactions(tags: [{ name: \"device-id\", values: [\"foodevice001\"] },{ name: \"data-type\", values: [\"temperature\"] },{ name: \"location\", values: [\"San Francisco, CA\"] },{ name: \"application-id\", values: [\"DePIN Network Alpha\"] }], order: ASC) {edges {node {idtags {namevalue}timestamp}}} } This query retrieves all temperature data from foodevice001 located in San Francisco, and orders the results by the upload timestamp. By using tags and timestamps, you can ensure your DePIN network maintains accurate data sequencing and retrieval across any blockchain."
    },
    {
      "path": "/build/d/guides/dynamic-nft",
      "content": " Learn how to create a dynamic NFT using mutable references. ;Dynamic NFTs Dynamic NFTs are NFTs whose metadata evolves over time. They are commonly used in: Gaming projects where in-game assets evolve as players progress. Loyalty programs where NFTs evolve as users accumulate points.In this guide, you'll create a SuperMon NFT that evolves during gameplay. The NFT starts with a basic appearance and can be \"upgraded\" twice. You will use the Irys Storage CLI to update the metadata, simulating the automatic changes that would occur through player interactions in an actual game.Mutable references Mutable references are a way to simulate \"mutability\". You start uploading a single transaction. This becomes the head of your transaction chain:Use a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); const receiptOne = await irys.upload(\"First TX\"); console.log(TX 1 uploaded https://gateway.irys.xyz/mutable/${receiptOne.id}); The chain can be updated at any time, and the original URL will always resolve to the most recent one. To \"update\" the chain, post a new transaction tagged with the transaction ID of the root transaction. const tags = [{ name: \"Root-TX\", value: receiptOne.id }]; const receiptTwo = await irys.upload(\"Second TX\", { tags: tags }); console.log(TX 2 uploaded https://gateway.irys.xyz/mutable/${receiptOne.id});When building a transaction chain, additions must be made using the same wallet that created the original transaction. This prevents unauthorized actors from maliciously modifying someone else’s transaction chain. Setup In this guide, you will build on the Base L2. Before starting, make sure you add Base Sepolia to your EVM wallet, pre-load some Base Sepolia tokens, and export your private key.While this guide uses Base Sepolia, the principles outlined can be adapted for deployment on any blockchain. Smart Contract You're building an NFT, which means you need a smart contract. Here's a simple one you can use to mint the NFT you'll create. // SPDX-License-Identifier: MIT pragma solidity ^0.8.0; // Import OpenZeppelin's ERC721 and ERC721URIStorage contracts // These URLs are compatible with Remix IDE import \"@openzeppelin/contracts/token/ERC721/ERC721.sol\"; import \"@openzeppelin/contracts/token/ERC721/extensions/ERC721URIStorage.sol\"; import \"@openzeppelin/contracts/access/Ownable.sol\"; contract SuperMon is ERC721URIStorage {uint256 private _tokenIdCounter;// No arguments in the constructor, the owner will be the contract deployerconstructor() ERC721(\"SuperMon\", \"SMON\") {_tokenIdCounter = 0;}// Mint function to create a new NFTfunction mint(address to, string memory uri) public {uint256 tokenId = _tokenIdCounter;_tokenIdCounter += 1;_safeMint(to, tokenId);_setTokenURI(tokenId, uri);} } To deploy the smart contract using Remix IDE: Open Remix IDE. Create a new Solidity file In the File Explorers pane, click on the Create New File icon. Name your file SuperMon.sol, and paste the smart contract in. Compile the contract Click on the Solidity Compiler icon in the sidebar. Select the compiler version that matches your contract's pragma (^0.8.0). Click Compile SuperMon.sol. Deploy the Contract Click on the Deploy & Run Transactions icon in the sidebar. In the ENVIRONMENT dropdown, select Injected Web3. MetaMask will prompt you to connect. Confirm the connection to your Remix session. Ensure SuperMon is selected in the CONTRACT dropdown. Click Deploy. MetaMask will ask for confirmation to proceed with the transaction.Uploading the ImagesRight-click on each of the above images and save them on your local drive. Next, fund the Irys Testnet with 0.1 Sepolia ETH to pay for your uploads.In all of these CLI examples, make sure to replace the value of the -w parameter with your own private key.irys fund 100000000000000000 \\-n testnet \\-t base-eth \\-w 6dd5e....54a120201cb6a \\--provider-url https://sepolia.base.orgThe fund command accepts a value in atomic units, 0.1 ETH is equal to 100000000000000000 in atomic units.Next, use the Irys Storage CLI to upload each of the images to Irys. irys upload image-level-1.png \\-n testnet \\-t base-eth \\-w 6dd5e....54a120201cb6a \\--tags Content-Type image/png \\--provider-url https://sepolia.base.org irys upload image-level-2.png \\-n testnet \\-t base-eth \\-w 6dd5e....54a120201cb6a \\--tags Content-Type image/png \\--provider-url https://sepolia.base.org irys upload image-level-3.png \\-n testnet \\-t base-eth \\-w 6dd5e....54a120201cb6a \\--tags Content-Type image/png \\--provider-url https://sepolia.base.orgUploading the Metadata Create three metadata files similar to the ones below. Make sure to change the value of the image field to match the URLs generated in the previous step. {\"name\": \"SuperMon\",\"symbol\": \"SMON\",\"image\": \"https://gateway.irys.xyz/QH3rksVhbFg5L9vvjGzb4POUibCEG-TGPInmofp-O-o\",\"description\": \"Super dooper, changing shapes, changing power\",\"attributes\": [{\"trait_type\": \"supermon-level\",\"value\": \"1\"}] } {\"name\": \"SuperMon\",\"symbol\": \"SMON\",\"image\": \"https://gateway.irys.xyz/QH3rksVhbFg5L9vvjGzb4POUibCEG-TGPInmofp-O-o\",\"description\": \"Super dooper, changing shapes, changing power\",\"attributes\": [{\"trait_type\": \"supermon-level\",\"value\": \"2\"}] } {\"name\": \"SuperMon\",\"symbol\": \"SMON\",\"image\": \"https://gateway.irys.xyz/QH3rksVhbFg5L9vvjGzb4POUibCEG-TGPInmofp-O-o\",\"description\": \"Super dooper, changing shapes, changing power\",\"attributes\": [{\"trait_type\": \"supermon-level\",\"value\": \"3\"}] } And upload just the first file using the Irys CLI. irys upload metadata-level-1.json \\-n testnet \\-t base-eth \\-w 6dd5e....54a120201cb6a \\--tags Content-Type application/json \\--provider-url https://sepolia.base.org The CLI will return a URL similar to https://gateway.irys.xyz/NDtKvjlmZL2iXUPmX6P-BuvtnvAEFkUiQWG8ToyK5FM. To convert that to a mutable references URL, interpolate it by adding /mutable/ after the domain and before the transaction ID. Your final URL will be similar to https://gateway.irys.xyz/mutable/NDtKvjlmZL2iXUPmX6P-BuvtnvAEFkUiQWG8ToyK5FM.Mint the NFT To mint your NFT in Remix: Return to Remix. Under \"Deployed Contracts\", locate your contract and expand it to see its functions. Under the Mint function, enter the wallet address you want to mint the NFT to and the metadata URL (e.g. https://gateway.irys.xyz/mutable/NDtKvjlmZL2iXUPmX6P-BuvtnvAEFkUiQWG8ToyK5FM) from the previous step. Click Transact.You can now view the NFT on the Opensea Testnet.Mutating the Metadata To now \"mutate\" the NFT, upload a new version of the metadata tagging it as having a Root-TX equal to the transaction ID of your first transaction. In my example, I pass the value of NDtKvjlmZL2iXUPmX6P-BuvtnvAEFkUiQWG8ToyK5FM, however make sure to change this to match your unique transaction ID. irys upload metadata-level-2.json \\-n devnet \\-t base-eth \\-w 6dd5e....54a120201cb6a \\--tags Content-Type application/json Root-TX NDtKvjlmZL2iXUPmX6P-BuvtnvAEFkUiQWG8ToyK5FM \\--provider-url https://sepolia.base.org Return to Opensea and request that it refresh your metadata.Give it a few minutes and your updated NFT should be visible.Free Metadata Uploads On Irys uploads of less than 100 KiB are free, which is more than enough for most metadata files. This means projects can let users \"evolve\" their NFTs without having to pay gas fees.Caching Wallets and NFT platforms typically cache metadata to optimize performance, this can affect the visibility of updates to dynamic NFTs. While OpenSea offers a feature for users to manually request metadata refreshes, not all platforms provide this level of control. When building dynamic NFT projects, make sure to thoroughly test and understand the implications of caching on your platform.Getting Help Any questions? Reach out to us in Discord."
    },
    {
      "path": "/build/d/guides/encrypting-with-lit",
      "content": " Use Lit Protocol with Irys to securely encrypt and manage your onchain data. ; ;Encrypting Onchain Data With Lit Protocol Use Lit Protocol with Irys to securely encrypt and manage your onchain data.Why This Matters Using Lit with Irys empowers developers with the ability to create innovative applications by combining secure, encrypted data with the power of data storage and execution.Lit Protocol Lit is a decentralized key management network for signing and encryption. Users can encrypt data and set custom decryption rules, such as owning specific NFTs, maintaining an ERC20 token balance, or any other logic they define.Irys Once encrypted, data can be uploaded onchain, offering guaranteed retrieval for as long as needed — whether for days or permanently. Only users who meet the defined decryption rules can access the data, making it ideal for secure and private use cases.Unlocking New Possibilities For Developers This opens up new use cases for builders, such as: Gating access to content Storing and securing private DePIN data Securely archiving sensitive AI data Encrypted content for decentralized social apps Decentralized identity verification Creating private data marketplaces Creating exclusive NFTsEncrypting DataThere are three steps to encrypting data: Obtain a wallet signature (AuthSig), which proves you own a wallet Define access control conditions for who can decrypt your data Connect to a Lit node and request that it encrypt your dataDecrypting DataThere are three steps to decrypting data: Obtain a wallet signature (AuthSig), which proves you own a wallet Retrieve data stored on Irys Connect to a Lit node and request that it decrypt your dataExamples This guide covers integrating Lit with Irys, both with Node.js on the server and React/Next.js in the browser.Node.js When working with Node.js, provide a private key when encrypting and decrypting data.The full code for this example is available in the GitHub repository. Users who prefer learning by example can start there.Installing npm install \\@lit-protocol/lit-node-client-nodejs \\@lit-protocol/constants \\@irys/upload \\@irys/upload-ethereum \\ethers \\siwe \\dotenvConnecting to Lit Protocol Connect to a Lit node on one of its active networks. Choose between Datil (mainnet), Datil-test (testnet), and Datil-dev (development). For this example, we'll use DatilDev as use is free and not rate-limited. ; ; let litNodeClientInstance: LitJsSdk.LitNodeClientNodeJs | null = null; async function getLitNodeClient(): Promise {if (litNodeClientInstance) return litNodeClientInstance;litNodeClientInstance = new LitJsSdk.LitNodeClientNodeJs({alertWhenUnauthorized: false,litNetwork: LitNetwork.DatilDev, // DatilDev network for free usagedebug: false,});await litNodeClientInstance.connect();return litNodeClientInstance; }Setting Access Control Rules Access control rules determine who can decrypt your data. Set conditions based on criteria like ETH or ERC20 balance, NFT ownership, or custom logic.ETH BalanceERC20 BalanceERC721 Ownership// Allow users with ≥ 0 ETH: function getAccessControlConditions(): object[] {return [{contractAddress: \"\",standardContractType: \"\",chain: \"ethereum\",method: \"eth_getBalance\",parameters: [\":userAddress\", \"latest\"],returnValueTest: {comparator: \">=\",value: \"000000000000000000\", // 0 ETH in wei},},]; }// Allow users with ≥ 100 DAI: function getAccessControlConditions(): object[] {return [{contractAddress: \"0x6B175474E89094C44Da98b954EedeAC495271d0F\", // DAI contractstandardContractType: \"ERC20\",chain: \"ethereum\",method: \"balanceOf\",parameters: [\":userAddress\"],returnValueTest: {comparator: \">=\",value: \"100000000000000000000\", // 100 DAI in wei},},]; }// Allow users owning any NFT from a contract function getAccessControlConditions(): object[] {return [{contractAddress: \"0xABC123...XYZ\", // ERC721 contract addressstandardContractType: \"ERC721\",chain: \"ethereum\",method: \"balanceOf\",parameters: [\":userAddress\"],returnValueTest: {comparator: \">\",value: \"0\",},},]; }For more advanced examples, see unified access control conditions.Encrypting Data Lit Protocol provides multiple methods to encrypt data, including strings, files, zip files. encryptString(): Encrypts a string. encryptToJson(): Encrypts a string or file and serializes the result to JSON. zipAndEncryptString(): Encrypts and compresses a string into a zip file. Useful for bundling multiple pieces of data. encryptFile() and zipAndEncryptFiles(): Encrypt a single file or multiple files. We will use encryptString() to encrypt a simple string: async function encryptData(dataToEncrypt: string): Promise {const authSig = await getAuthSig();const accessControlConditions = getAccessControlConditions();const litNodeClient = await getLitNodeClient();const { ciphertext, dataToEncryptHash } = await LitJsSdk.encryptString({ accessControlConditions, dataToEncrypt },litNodeClient);return [ciphertext, dataToEncryptHash]; } The encryptString() function encrypts your data according to the specified access control conditions, and returns: ciphertext: The encrypted string. dataToEncryptHash: The hash of the original string, ensuring data integrity.Storing Data on Irys When storing encrypted data on Irys, store it as a JSON object with three components: ciphertext: The encrypted version of your data. dataToEncryptHash: A hash of the original data, which helps verify its integrity during decryption. accessControlConditions: The rules governing who can decrypt the data. async function storeOnIrys(cipherText: string, dataToEncryptHash: string): Promise {const irysUploader = await getIrysUploader();const dataToUpload = {cipherText,dataToEncryptHash,accessControlConditions: getAccessControlConditions(),};try {const tags = [{ name: \"Content-Type\", value: \"application/json\" }];const receipt = await irysUploader.upload(JSON.stringify(dataToUpload), { tags });return receipt?.id || \"\";} catch (error) {console.error(\"Error uploading data: \", error);return \"\";} }Downloading Data from Irys To retrieve your stored data, use the transaction ID returned at upload. async function retrieveFromIrys(id: string): Promise {const gatewayAddress = \"https://gateway.irys.xyz/\";const url = ${gatewayAddress}${id};try {const response = await fetch(url);if (!response.ok) throw new Error(Failed to retrieve data for ID: ${id});const data = await response.json();return [data.cipherText, data.dataToEncryptHash, data.accessControlConditions];} catch (error) {console.error(\"Error retrieving data: \", error);return [\"\", \"\", []];} }Decrypting Data Use the decryptToString() function to decrypt the data. This requires the ciphertext, its hash, access control conditions, and session signatures. async function decryptData(ciphertext: string,dataToEncryptHash: string,accessControlConditions: object[] ): Promise {const litNodeClient = await getLitNodeClient();const sessionSigs = await litNodeClient.getSessionSigs({chain: \"ethereum\",resourceAbilityRequests: [{resource: new LitAccessControlConditionResource(\"*\"),ability: LitAbility.AccessControlConditionDecryption,},],authNeededCallback: async (params: any) => {const toSign = await createSiweMessageWithRecaps({uri: params.uri,expiration: params.expiration,resources: params.resourceAbilityRequests,walletAddress: await (await new ethers.Wallet(process.env.PRIVATE_KEY!)).getAddress(),nonce: await litNodeClient.getLatestBlockhash(),litNodeClient,});return await generateAuthSig({signer: new ethers.Wallet(process.env.PRIVATE_KEY!),toSign,});},});const decryptedString = await LitJsSdk.decryptToString({accessControlConditions,chain: \"ethereum\",ciphertext,dataToEncryptHash,sessionSigs,},litNodeClient);return decryptedString; }Next.js When working with Lit in the browser, the private key will be linked via the user's wallet extension.The full code for this example, including a complete UI, is available in the GitHub repository. This guide focuses on the functions which handle interactions with Lit Protocol and Irys, but does not cover how to build and setup a UI.Installing npm install \\@lit-protocol/lit-node-client \\@irys/web-upload \\@irys/web-upload-ethereum \\@irys/web-upload-ethereum-ethers-v6 \\ethersConnecting to Lit Protocol Connect to a Lit node on one of its active networks. Choose between Datil (mainnet), Datil-test (testnet), and Datil-dev (development). For this example, we'll use DatilDev as use is free and not rate-limited. ; ; const litClient = new LitNodeClient({litNetwork: \"datil-dev\", });Setting Access Control Rules Access control rules determine who can decrypt your data. Set conditions based on criteria like ETH or ERC20 balance, NFT ownership, or custom logic.ETH BalanceERC20 BalanceERC721 Ownership// Allow users with ≥ 0 ETH: function getAccessControlConditions(): object[] {return [{contractAddress: \"\",standardContractType: \"\",chain: \"ethereum\",method: \"eth_getBalance\",parameters: [\":userAddress\", \"latest\"],returnValueTest: {comparator: \">=\",value: \"000000000000000000\", // 0 ETH in wei},},]; }// Allow users with ≥ 100 DAI: function getAccessControlConditions(): object[] {return [{contractAddress: \"0x6B175474E89094C44Da98b954EedeAC495271d0F\", // DAI contractstandardContractType: \"ERC20\",chain: \"ethereum\",method: \"balanceOf\",parameters: [\":userAddress\"],returnValueTest: {comparator: \">=\",value: \"100000000000000000000\", // 100 DAI in wei},},]; }// Allow users owning any NFT from a contract function getAccessControlConditions(): object[] {return [{contractAddress: \"0xABC123...XYZ\", // ERC721 contract addressstandardContractType: \"ERC721\",chain: \"ethereum\",method: \"balanceOf\",parameters: [\":userAddress\"],returnValueTest: {comparator: \">\",value: \"0\",},},]; }For more advanced examples, see unified access control conditions.Encrypting Data Lit Protocol provides multiple methods to encrypt data, including strings, files, zip files. encryptString(): Encrypts a string. encryptToJson(): Encrypts a string or file and serializes the result to JSON. zipAndEncryptString(): Encrypts and compresses a string into a zip file. Useful for bundling multiple pieces of data. encryptFile() and zipAndEncryptFiles(): Encrypt a single file or multiple files. We will use encryptString() to encrypt a string: export const encryptString = async (text: string): Promise => {await litClient.connect();const accessControlConditions = getAccessControlConditions();const { ciphertext, dataToEncryptHash } = await LitJsSdk.encryptString({accessControlConditions,dataToEncrypt: text,},litClient);console.log({ ciphertext, dataToEncryptHash });return { ciphertext, dataToEncryptHash }; }; The encryptString() function encrypts your data according to the specified access control conditions, and returns: ciphertext: The encrypted string. dataToEncryptHash: The hash of the original string, ensuring data integrity.Storing Data on Irys When storing encrypted data on Irys, store it as JSON objet with three components: ciphertext: The encrypted version of your data. dataToEncryptHash: A hash of the original data, which helps verify its integrity during decryption. accessControlConditions: The rules governing who can decrypt the data. export const uploadToIrys = async (cipherText: string, dataToEncryptHash: string): Promise => {const irysUploader = await getIrysUploader();const dataToUpload = {cipherText: cipherText,dataToEncryptHash: dataToEncryptHash,accessControlConditions: getAccessControlConditions(),};try {const tags = [{ name: \"Content-Type\", value: \"application/json\" }];const receipt = await irysUploader.upload(JSON.stringify(dataToUpload), { tags });return receipt?.id ? ${gatewayAddress}${receipt.id} : \"\";} catch (error) {console.error(\"Error uploading data: \", error);throw error;} };Downloading Data from Irys To retrieve your stored data, you can use the transaction ID returned during the upload. export const downloadFromIrys = async (id: string): Promise => {const url = ${gatewayAddress}${id};try {const response = await fetch(url);if (!response.ok) throw new Error(Failed to retrieve data for ID: ${id});const data = await response.json();const ciphertext = data.cipherText;const dataToEncryptHash = data.dataToEncryptHash;return [ciphertext, dataToEncryptHash, data.accessControlConditions];} catch (error) {console.error(\"Error retrieving data: \", error);return [\"\", \"\", []];} };Decrypting Data Use the decryptToString() function to decrypt the data. This requires the ciphertext, its hash, access control conditions, and session signatures. export const decryptData = async (encryptedText: string, dataToEncryptHash: string): Promise => {await litClient.connect();const provider = new ethers.BrowserProvider(window.ethereum);const signer = await provider.getSigner();const walletAddress = await signer.getAddress();const latestBlockhash = await litClient.getLatestBlockhash();const authNeededCallback = async (params: any) => {if (!params.uri) throw new Error(\"uri is required\");if (!params.expiration) throw new Error(\"expiration is required\");if (!params.resourceAbilityRequests) throw new Error(\"resourceAbilityRequests is required\");const toSign = await createSiweMessageWithRecaps({uri: params.uri,expiration: params.expiration,resources: params.resourceAbilityRequests,walletAddress: walletAddress,nonce: latestBlockhash,litNodeClient: litClient,});const authSig = await generateAuthSig({signer: signer,toSign,});return authSig;};const litResource = new LitAccessControlConditionResource(\"*\");const sessionSigs = await litClient.getSessionSigs({chain: \"ethereum\",resourceAbilityRequests: [{resource: litResource,ability: LitAbility.AccessControlConditionDecryption,},],authNeededCallback,});const decryptedString = await LitJsSdk.decryptToString({accessControlConditions: getAccessControlConditions(),chain: \"ethereum\",ciphertext: encryptedText,dataToEncryptHash,sessionSigs,},litClient);return decryptedString; };Getting Help Any questions? Reach out to us in Discord."
    },
    {
      "path": "/build/d/guides/irys-react",
      "content": " Using the Irys SDK with create-react-app. ;Using Irys With npx create-react-appIf you're using React with Vite, polyfills are handled differently. You'll need to follow [this guideinstead](./vite).Irys is fully compatible with React, however, if you’re using npx create-react-app to create your project, you will need to do some additional configuration and installation. This guide details how to create a new React project and add Irys support. If you already have a React project, skip the first step.Step 1: Create a New React Project Create a new directory for your project, cd into it, and create your React project: mkdir irys-react cd irys-react npx create-react-app .Step 2: Install the Irys SDK, Ethers, and Axios npm install \\@irys/web-upload \\@irys/web-upload-ethereum \\@irys/web-upload-ethereum-ethers-v6 \\ethers@6 \\axiosStep 3: Initialize the Irys Uploader In your App.js file, write an initialization function that sets up an Irys uploader. The following code shows how to use ethers6. We also have code examples for different providers. ; ; ; ; ; function App() {const [walletStatus, setWalletStatus] = useState(\"Not connected\");const [irysStatus, setIrysStatus] = useState(\"Not connected\");const connectWallet = async () => {try {const provider = new ethers.BrowserProvider(window.ethereum);await provider.send(\"eth_requestAccounts\", []);const signer = await provider.getSigner();const address = await signer.getAddress();setWalletStatus(Connected: ${address});} catch (error) {console.error(\"Error connecting to wallet:\", error);setWalletStatus(\"Error connecting to wallet\");}};const connectIrys = async () => {try {const provider = new ethers.BrowserProvider(window.ethereum);const irysUploader = await WebUploader(WebEthereum).withAdapter(EthersV6Adapter(provider));setIrysStatus(Connected to Irys: ${irysUploader.address});} catch (error) {console.error(\"Error connecting to Irys:\", error);setIrysStatus(\"Error connecting to Irys\");}};return (Connect Wallet{walletStatus}Connect Irys{irysStatus}); } export default App; When you try to run the app, you see this similar to this BREAKING CHANGE: webpack < 5 used to include polyfills for node.js core modules by default. To fix this, you'll need to include Node.js polyfills that are not included by default.Step 4: Install React-App-Rewired and Polyfills Install react-app-rewired, a package that allows you to customize the Webpack configuration to handle the polyfills, and the missing dependencies: npm install react-app-rewired npm install --save-dev crypto-browserify stream-browserify assert stream-http https-browserify os-browserify url buffer process npm install browserify-zlib path-browserify path npm install node-polyfill-webpack-plugin --save-devStep 5: Create the Webpack Configuration Override At the root level of your project, create a new file called config-overrides.js and paste the following: const NodePolyfillPlugin = require(\"node-polyfill-webpack-plugin\"); const webpack = require(\"webpack\"); module.exports = function override(config) {config.plugins = (config.plugins || []).concat([new NodePolyfillPlugin(),new webpack.ProvidePlugin({process: \"process/browser.js\",}),]);const fallback = config.resolve.fallback || {};Object.assign(fallback, {crypto: require.resolve(\"crypto-browserify\"),stream: require.resolve(\"stream-browserify\"),assert: require.resolve(\"assert\"),http: require.resolve(\"stream-http\"),https: require.resolve(\"https-browserify\"),os: require.resolve(\"os-browserify\"),url: require.resolve(\"url\"),zlib: require.resolve(\"browserify-zlib\"),buffer: require.resolve(\"buffer\"),path: require.resolve(\"path-browserify\"),});config.resolve.fallback = fallback;config.resolve.extensions = [\".js\", \".jsx\", \".json\", \".mjs\", \".wasm\", \".css\"];return config; };Step 6: Update package.json Scripts Modify your package.json to use the new Webpack configuration. Look for this code block:\"scripts\": {\"start\": \"react-scripts start\",\"build\": \"react-scripts build\",\"test\": \"react-scripts test\",\"eject\": \"react-scripts eject\"}, and replace it with this block: \"scripts\": {\"start\": \"react-app-rewired start\",\"build\": \"react-app-rewired build\",\"test\": \"react-app-rewired test\",\"eject\": \"react-scripts eject\" },Step 7: Restart Your React App Quit the React development server if it's running and restart it: npm start You should now be good to go! Your React app is set up with all necessary polyfills and is ready to use the Irys SDK."
    },
    {
      "path": "/build/d/guides/monitor-account-balance",
      "content": " Monitor your account balance using JavaScript, our CLI, or cURL ;Monitor Node Balance With A Script Irys's upfront funding simplifies uploading data by allowing you to pre-fund your uploads. This eliminates the need for individual funding calls for each upload as the loaded balance is automatically deducted from with each upload. To keep track of your loaded balance, users commonly create scripts that periodically check their balance and provide notifications when it approaches zero. This guide offers examples of how to monitor your balance using: JavaScript Command Line Interface (CLI) cURL. These three techniques are all equally effective options.JavaScriptThe following getIrysUploader() function is for using the Ethereum token only, we also have examples covering all of the tokens we support for payment.; ; dotenv.config(); const getIrysUploader = async () => {const irysClient= await EthereumNodeIrys().withWallet(process.env.PRIVATE_KEY);console.log(Connected to Irys from ${irysClient.address});return irysClient; }; const checkBalance = async () => {const irys = await getIrysUploader();// Get loaded balance in atomic unitsconst atomicBalance = await irys.getLoadedBalance();// Convert balance to standard unitsconst convertedBalance = irys.utils.fromAtomic(atomicBalance);return convertedBalance; }; const checkAndPrintBalance = async () => {const balance = await checkBalance();const threshold = 0.1; // 10% thresholdif (Math.abs(balance) /account/balance/?address=. For example to check the MATIC balance of the wallet with address 0xaC568a981B1370B2e1bAA8cE30BD5AC9E28C572D`, you would use the command https://testnet.irys.xyz/account/balance/matic?address=0xaC568a981B1370B2e1bAA8cE30BD5AC9E28C572D Just as with our CLI, you don’t need to provide your private key. This version is also more streamlined than the CLI version as you don’t need to include the provider URL when checking the Devnet balances. #!/bin/bashDefine your variables address=\"0xaC568a981B1370B2e1bAA8cE30BD5AC9E28C572D\" # Public wallet address node_address=\"https://testnet.irys.xyz\" token=\"token\" balance_output=\"\";Create the API endpoint URL balancecheckurl=\"${node_address}/account/balance/${token}?address=${address}\"Make the cURL request and capture the response balanceoutput=$(curl -s \"$balancecheck_url\")Parse the balance from the response using awk parsedbalance=$(echo \"$balanceoutput\" | awk -F'\"' '{print $4}')Define the decimal factor for conversion (this works for MATIC and others with 18 decimals) decimal_factor=1000000000000000000For Solana currencies with 9 decimals, use decimalfactor=1000000000Convert parsedbalance to standard units balanceinstandardunits=$(awk -v parsedbalance=\"$parsedbalance\" -v decimalfactor=\"$decimalfactor\" 'BEGIN{printf \"%.18f\", parsedbalance/decimal_factor}')Define your threshold in standard units threshold=0.1Check if balanceinstandard_units is within a threshold of 0 isclosetozero=$(awk -v balance=\"$balanceinstandardunits\" -v threshold=\"$threshold\" 'BEGIN{if(balance < threshold) print 1; else print 0}') if [ $iscloseto_zero -eq 1 ]; thenecho \"Balance ${balanceinstandard_units} is within $(echo \"$threshold*100\" | bc -l)% of 0, please fund.\" elseecho \"Balance ${balanceinstandard_units} funding not yet needed\" fi To run a bash script periodically, use cron. Assuming you saved the above script as a file checkBalance.sh, open up your crontab file using crontab -e and then add an entry to call the script periodically. To call it every 30 minutes, you’d add the following: /30* * * /path/to/your/script/checkBalance.sh"
    },
    {
      "path": "/build/d/guides/uploading-nfts",
      "content": " How to upload NFT assets to Irys ;Uploading NFTs to Irys When you use Irys to store NFT assets, you’re guaranteed your NFT will be both permanent and immutable. Here’s how you do it.NFT AssetsThere are three parts to an NFT: Smart contract NFT metadata NFT assets The smart contract stores a pointer to the NFT metadata, and then the NFT metadata contains links to the NFT assets. In the example above, there is a name and description that are shown on platforms like Opensea when the NFT is viewed. The image parameter points to a static image of the NFT. You can also add an optional animation_url that points to a video, song, or HTML animation file.Creating an NFT Three steps to creating an NFT: Upload your assets to Irys. Embed the URLs to the assets in NFT metadata. Upload metadata to Irys. Use the metadata URL to mint your NFT.Uploading Assets (SDK) After installing the Irys SDK, upload your assets with:Use a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.; const uploadImage = async () => {const irys = await getIrysUploader();const fileToUpload = \"./myNFT.png\";// Get size of fileconst { size } = await fs.promises.stat(fileToUpload);// Get cost to upload \"size\" bytesconst price = await irys.getPrice(size);console.log(Uploading ${size} bytes costs ${irys.utils.fromAtomic(price)} ${token});await irys.fund(price);// Upload metadatatry {const response = await irys.uploadFile(fileToUpload);console.log(File uploaded ==> https://gateway.irys.xyz/${response.id});} catch (e) {console.log(\"Error uploading file \", e);} };Uploading Assets (CLI) Alternatively, you can upload using our Storage CLI. irys upload myNFT.png \\-n testnet \\-t ethereum \\-w bf20......c9885307 \\--tags Content-Type image/png \\--provider-url https://rpc.sepolia.devCreating Metadata Embed the URLs generated from the above into your NFT metadata. {\"name\": \"My NFT\",\"symbol\": \"MNFT\",\"description\": \"To the moooooonnnn\",\"image\": \"https://gateway.irys.xyz/737m0bA1kW4BlIJOgkOGUpHAAI-3Ec9bdo8SxTFKI\", }Uploading Metadata (SDK) Finally, upload your NFT metadata to Irys and use the URL generated to mint the NFT. ; ; const uploadMetadata = async () => {const irys = await getIrysUploader();const fileToUpload = \"./metadata.json\";const tags = [{ name: \"Content-Type\", value: \"application/json\" }];// Get size of fileconst { size } = await fs.promises.stat(fileToUpload);// Get cost to upload \"size\" bytesconst price = await irys.getPrice(size);console.log(Uploading ${size} bytes costs ${irys.utils.fromAtomic(price)} ${token});await irys.fund(price);// Upload metadatatry {const response = await irys.uploadFile(fileToUpload, { tags: tags });console.log(File uploaded ==> https://gateway.irys.xyz/${response.id});} catch (e) {console.log(\"Error uploading file \", e);} };Uploading Metadata (CLI) Alternatively, you can upload using our Storage CLI. irys upload metadata.json \\-n testnet \\-t ethereum \\-w bf20......c9885307 \\--tags Content-Type application/json \\--provider-url https://rpc.sepolia.dev `"
    },
    {
      "path": "/build/d/guides/vite",
      "content": " Using the Irys SDK with create-react-app and Vite.Using Irys With React + Vite This guide covers how to set up an Irys project using React + Vite.Step 1: Setup a New Project Create a new directory for your project, navigate into it, and initialize it with Vite: mkdir irys-vite cd irys-vite npm create vite@latest . Choose React and select either TypeScript or JavaScript. After selecting the framework, run: npm installStep 2: Install the Irys SDK, Ethers, and Axios Install the necessary packages, including the Irys SDK, Ethers, and Axios: npm install \\@irys/web-upload \\@irys/web-upload-ethereum \\@irys/web-upload-ethereum-ethers-v6 \\ethers@6 \\axiosStep 3: Initialize the Irys Uploader In your App.tsx file, write an initialization function to set up an Irys uploader using Ethers v6: ; ; ; ; ; function App() {const [walletStatus, setWalletStatus] = useState(\"Not connected\");const [irysStatus, setIrysStatus] = useState(\"Not connected\");const connectWallet = async () => {console.log(\"connect wallet\");if (typeof window.ethereum === 'undefined') {console.error(\"No Ethereum provider found. Please install MetaMask or another wallet.\");setWalletStatus(\"No Ethereum provider found. Please install MetaMask or another wallet.\");return;}try {const provider = new ethers.BrowserProvider(window.ethereum);await provider.send(\"eth_requestAccounts\", []);const signer = await provider.getSigner();const address = await signer.getAddress();setWalletStatus(Connected: ${address});} catch (error) {console.error(\"Error connecting to wallet:\", error);setWalletStatus(\"Error connecting to wallet\");}};const connectIrys = async () => {if (typeof window.ethereum === 'undefined') {console.error(\"No Ethereum provider found. Please install MetaMask or another wallet.\");setIrysStatus(\"No Ethereum provider found. Please install MetaMask or another wallet.\");return;}try {const provider = new ethers.BrowserProvider(window.ethereum);const irysUploader = await WebUploader(WebEthereum).withAdapter(EthersV6Adapter(provider));setIrysStatus(Connected to Irys: ${irysUploader.address});} catch (error) {console.error(\"Error connecting to Irys:\", error);setIrysStatus(\"Error connecting to Irys\");}};return (Connect Wallet{walletStatus}Connect Irys{irysStatus}); } export default App;Step 4: Install Node Polyfills for Vite Vite does not automatically polyfill Node.js core modules like crypto, stream, os, or path. To fix compatibility issues, install the necessary polyfill packages: npm install --save-dev \\crypto-browserify \\stream-browserify \\os-browserify \\path-browserify \\vite-plugin-node-polyfillsStep 5: Update vite.config.js Modify your vite.config.js to use vite-plugin-node-polyfills to handle the polyfills required for Node.js core modules: import { defineConfig } from 'vite'; import react from '@vitejs/plugin-react'; import { nodePolyfills } from 'vite-plugin-node-polyfills'; // https://vitejs.dev/config/ export default defineConfig({plugins: [react(),nodePolyfills({// Enable polyfills for specific globals and modulesglobals: {Buffer: true,global: true,process: true,},protocolImports: true, // Polyfill node: protocol imports}),],resolve: {alias: {// Polyfill Node.js core modulescrypto: 'crypto-browserify',stream: 'stream-browserify',os: 'os-browserify/browser',path: 'path-browserify',},}, });Step 6: Restart Vite Development Server After making these changes, restart your development server: npm run dev Your React + Vite project should now be set up correctly to use the Irys SDK and handle all necessary Node.js polyfills."
    },
    {
      "path": "/build/d/irys-in-the-browser",
      "content": " Using the Irys class to interact with Irys from the browser ;Irys in The Browser The Irys SDK reduces dependency bloat by providing dedicated packages for each token. Your install statements, import and connection code will differ depending on the token used for payment and the provider used. Choose the code for your provider:If you're using Irys with React, followthese extra setup steps. If you're using Irys with Vite, follow these steps.Ethers v5 |Ethers v6 | Viem v2 | Solana | Aptos EVM Chains When connecting from an EVM chain, your connection code will differ based on the token you're using. The examples below use Ethereum and the WebEthereum class. To change tokens, use one from the following list. | Token| Class Name| | ----------------- | ---------------- | | Polygon| WebMatic| | Binance Coin| WebBNB| | Avalanche C-Chain | WebAvalanche| | Base Ethereum| WebBaseEth| | USDC (on Ethereum)| WebUSDCEth| | Arbitrum| WebArbitrum| | Chainlink| WebChainlink| | USDC (on Polygon) | WebUSDCPolygon | | Berachain| WebBera| | Scroll Ethereum| WebScrollEth| | Linea Ethereum| WebLineaEth| | IoTeX| WebIotex| | Ethereum| WebEthereum|Ethers v5 Installing: npm install \\@irys/web-upload \\@irys/web-upload-ethereum \\ethers@5 Importing & Configuring: ; ; const getIrysUploader = async () => {const provider = new ethers.providers.Web3Provider(window.ethereum);const irysUploader = await WebUploader(WebEthereum).withProvider(provider);return irysUploader; };Ethers v6 Installing: npm install \\@irys/web-upload \\@irys/web-upload-ethereum \\@irys/web-upload-ethereum-ethers-v6 \\ethers@6 Importing & Configuring: ; ; ; ; const getIrysUploader = async () => {const provider = new ethers.BrowserProvider(window.ethereum);const irysUploader = await WebUploader(WebEthereum).withAdapter(EthersV6Adapter(provider));return irysUploader; };Viem v2 Installing: npm install \\@irys/web-upload \\@irys/web-upload-ethereum \\@irys/web-upload-ethereum-viem-v2 \\viem Importing & Configuring: ; ; ; const getIrysUploader = async () => {const [account] = await window.ethereum.request({ method: \"eth_requestAccounts\",});const provider = createWalletClient({account,chain: sepolia,transport: custom(window.ethereum),});const publicClient = createPublicClient({chain: sepolia,transport: custom(window.ethereum),});const irysUploader = await WebUploader(WebEthereum).withAdapter(ViemV2Adapter(provider, { publicClient }));return irysUploader; };Solana Installing: npm install \\@irys/web-upload \\@irys/web-upload-solana@solana/wallet-adapter-base \\@solana/wallet-adapter-react \\@solana/wallet-adapter-react-ui \\@solana/wallet-adapter-wallets \\@solana/web3.js Importing & Configuring: The Solana library uses the React provider pattern. Start by setting up a top-level file named ClientProviders.tsx that wraps all your child components. \"use client\"; ; ; ; ; ; ; require(\"@solana/wallet-adapter-react-ui/styles.css\"); export default function ClientProviders({ children }: { children: ReactNode }) {const network = WalletAdapterNetwork.Devnet;const endpoint = useMemo(() => clusterApiUrl(network), [network]);const wallets = useMemo(() => [new UnsafeBurnerWalletAdapter()],[network]);return ({children}); } Then load this component via layout.tsx: ; ; ; const inter = Inter({ subsets: [\"latin\"] }); export default function RootLayout({children, }: Readonly) {return ({children}); } Solana's wallet-adapter library make it easy to manage wallet connections. Create a component using this library to connect to a Solana wallet: \"use client\"; ; ; import \"@solana/wallet-adapter-react-ui/styles.css\"; const ConnectSolana: React.FC = () => {const [isClient, setIsClient] = useState(false);// Prevent hydration errors by ensuring this runs only on the client sideuseEffect(() => {setIsClient(true);}, []);if (!isClient) {return null;}return ({/* Solana wallet connect button */}{/* Solana wallet disconnect button */}); }; export default ConnectSolana; Then create a component called ConnectIrys.tsx that connects to an Irys bundler. \"use client\"; ; ; ; ; const getIrysUploader = async (wallet: any) => {try {const irysUploader = await WebUploader(WebSolana).withProvider(wallet);return irysUploader;} catch (error) {console.error(\"Error connecting to Irys:\", error);throw new Error(\"Error connecting to Irys\");} }; const ConnectIrys = (): JSX.Element => {const wallet = useWallet();const [isConnected, setIsConnected] = useState(false);const connectToIrys = async () => {if (!wallet) {console.log(\"Wallet not connected\");return;}try {const irysUploader = await getIrysUploader(wallet);console.log(Connected to Irys from ${irysUploader.address});setIsConnected(true);} catch (error) {console.log(\"Error connecting to Irys\");}};return ({isConnected ? \"Connected to Irys\" : \"Connect Irys\"}); }; export default ConnectIrys; And load them all through your page.tsx file: ; ; ; export default function Home() {return (); }Aptos Start by scaffolding a blank Aptos project using npx create-aptos-dapp. Next, install the following packages needed by Irys: npm install \\@irys/web-upload \\@irys/web-upload-aptos \\axios Replace your App.tsx file with the following: ; ; ; ; // Radix UI Components ; ; function App() {const { connected } = useWallet();const wallet = useWallet();const [irysStatus, setIrysStatus] = useState(\"Not connected\");const connectIrys = async () => {console.log(\"connect irys called\");console.log({wallet})try {const irysUploader = await WebUploader(WebAptos).withProvider(wallet);console.log({irysUploader})setIrysStatus(Connected to Irys: ${irysUploader.address});} catch (error) {console.error(\"Error connecting to Irys:\", error);setIrysStatus(\"Error connecting to Irys\");}};return ({connected ? ({irysStatus === \"Not connected\" ? \"Connect Irys\" : irysStatus}) : (To get started, connect a wallet)}); } export default App; The npx create-aptos-dapp CLI uses React + Vite. Vite does not automatically polyfill Node.js core modules like crypto, stream, os, or path. To fix compatibility issues, install the necessary polyfill packages: npm install --save-dev \\crypto-browserify \\stream-browserify \\os-browserify \\path-browserify \\vite-plugin-node-polyfills Modify your vite.config.js to use vite-plugin-node-polyfills to handle the polyfills required for Node.js core modules: ; ; ; ; // https://vitejs.dev/config/ export default defineConfig({plugins: [react(),nodePolyfills({// Enable polyfills for specific globals and modulesglobals: {Buffer: true,global: true,process: true,},protocolImports: true, // Polyfill node: protocol imports}),],resolve: {alias: {// Polyfill Node.js core modulescrypto: \"crypto-browserify\",stream: \"stream-browserify\",os: \"os-browserify/browser\",path: \"path-browserify\",\"@\": path.resolve(__dirname, \"./frontend\"),},},build: {outDir: \"dist\", // Output directory},server: {open: true,}, }); After making these changes, restart your development server: npm run dev `"
    },
    {
      "path": "/build/d/migrating",
      "content": " Quickstart with the Irys SDK ;Migrating to the Irys L1 The Irys testnet is now live with support for permanent data uploads, and temporary data support coming soon. In the coming weeks, we’ll also introduce the IrysVM and Programmable Data. Irys provides early access to all these new features for developers building on our platform. At mainnet launch, all data uploaded to bundlers will be migrated from testnet to mainnet, with no changes to transaction IDs.If you're not ready to migrate yet, you do not have to do anything. Irys's bundlers and gateway for Arweave will continue to operate as normal. How to Migrate The new Irys Bundler SDK reduces dependency bloat by providing dedicated packages for each token. Previously, Irys used a single import statement and connection code regardless of token, with our new SDK, code is unique per token. Migrating your code is simple and straight-forward.NodeJS Change This: ; const getIrys = async () => {const irys = new Irys({network: \"mainnet\",token: \"ethereum\",key: process.env.PRIVATE_KEY,});return irys; }; To This: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Ethereum).withWallet(process.env.PRIVATE_KEY);return irysUploader; };The above code is for ethereum only, we also have examples covering all supported tokens. Browser Change This: ; ; const getWebIrys = async () => {await window.ethereum.enable();const provider = new providers.Web3Provider(window.ethereum);const wallet = { rpcUrl: rpcUrl, name: \"ethersv5\", provider: provider };const webIrys = new WebIrys({ network: \"mainnet\", token: \"ethereum\", wallet });await webIrys.ready();return webIrys; }; To This: ; ; ; const getIrysUploader = async () => {const provider = new ethers.providers.Web3Provider(window.ethereum);const irysUploader = await WebUploader(WebEthereum).withProvider(EthereumEthersv5(provider));return irysUploader; };The above code is for ethereum with ethers v5 only, we also have examples covering all supported tokens and providers. Support Need help or just have questions? Come find us in Discord."
    },
    {
      "path": "/build/d/networks",
      "content": " Irys testnet and devnet ;Networks Irys has two networks: Testnet: Uploads are paid for with real tokens. At mainnet launch, all data uploaded to testnet bundlers will be migrated to mainnet, with no changes to transaction IDs. Devnet: Uploads are paid for with free faucet tokens. Data is deleted after ~60 days.Connecting to TestnetThe following code is for using ethereum only, we also have examples covering all of the tokens we support for payment.; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Ethereum).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Connecting to DevnetThe following code is for using ethereum only, we also have examples covering all of the tokens we support for payment.To connect to devnet, append the functions withRpc() and devnet(). RPC URLs are required when using devnet. ; ; const getIrysUploader = async () => {// RPC URLs change often. Use a current one from https://chainlist.org/const rpcURL = \"\";const irysUploader = await Uploader(Ethereum).withWallet(process.env.PRIVATE_KEY).withRpc(rpcURL).devnet();return irysUploader; }; `"
    },
    {
      "path": "/build/d/quickstart",
      "content": " Quickstart with the Irys SDK ;Irys SDK {/*Irys is currently in alpha testnet. At mainnet launch, all data uploaded to bundlers will be migrated from testnet to mainnet, with no changes to transaction IDs.*/}Installing This example uses ETH for payment. You can use any of the supported tokens. Install using npm: npm install @irys/upload @irys/upload-ethereum {/*If you get a warning saying bigint: Failed to load bindings, pure JS will be used (try npm run rebuild?) duringinstall, it can be safely ignored. For details on how make it go away, see our [troubleshootingguide](/build/d/troubleshooting#bigint).*/}Connecting to the network The following code is for using ETH for payment, we also have examples covering all supported tokens. ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Ethereum).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Funding Irys Fund your account on the Irys network using any of our supported tokens: const fundAccount = async () => {const irysUploader = await getIrysUploader();try {const fundTx = await irysUploader.fund(irysUploader.utils.toAtomic(0.05));console.log(Successfully funded ${irysUploader.utils.fromAtomic(fundTx.quantity)} ${irysUploader.token});} catch (e) {console.log(\"Error when funding \", e);} };UploadingUploading Data const uploadData = async () => {const irysUploader = await getIrysUploader();const dataToUpload = \"hirys world.\";try {const receipt = await irysUploader.upload(dataToUpload);console.log(Data uploaded ==> https://gateway.irys.xyz/${receipt.id});} catch (e) {console.log(\"Error when uploading \", e);} };Uploading a File const uploadFile = async () => {const irysUploader = await getIrysUploader();// Your fileconst fileToUpload = \"./myImage.png\";const tags = [{ name: \"application-id\", value: \"MyNFTDrop\" }];try {const receipt = await irysUploader.uploadFile(fileToUpload, { tags: tags });console.log(File uploaded ==> https://gateway.irys.xyz/${receipt.id});} catch (e) {console.log(\"Error when uploading \", e);} };Uploading a Folder You can upload a group of files as a single transaction from both the server and the browser.When uploading a folder, files can be accessed either directly athttps://gateway.irys.xyz/:transactionId or https://gateway.irys.xyz/:manifestId/:fileNameconst uploadFolder = async () => {const irysUploader = await getIrysUploader();// Upload an entire folderconst folderToUpload = \"./my-images/\"; // Path to foldertry {const receipt = await irysUploader.uploadFolder(\"./\" + folderToUpload, {indexFile: \"\", // Optional index file (file the user will load when accessing the manifest)batchSize: 50, // Number of items to upload at oncekeepDeleted: false, // whether to keep now deleted items from previous uploads}); // Returns the manifest IDconsole.log(Files uploaded. Manifest ID ${receipt.id});} catch (e) {console.log(\"Error when uploading \", e);} };3rd-Party Build ToolsParcel If using Parcel, you will need to manually enable package exports by adding the following to the package.json file in your project root directory. {\"@parcel/resolver-default\": {\"packageExports\": true} } `"
    },
    {
      "path": "/build/d/rest-api/account",
      "content": " Account APIAccount API These routes query the Irys Labs bundler for account details, such as retrieving account balances. "
    },
    {
      "path": "/build/d/rest-api/chunks",
      "content": "Chunk API These routes are for posting chunks to the Irys Labs bundler and querying for information about posted chunks. "
    },
    {
      "path": "/build/d/rest-api/general",
      "content": "General API These routes query the Irys Labs bundler for general status information. "
    },
    {
      "path": "/build/d/rest-api/price",
      "content": "Price API This route queries the Irys Labs bundler to determine the cost to upload a set number of bytes. "
    },
    {
      "path": "/build/d/rest-api/transactions",
      "content": "Transaction API These routes post new transactions to the Irys Labs bundler and also query the bundler for information about transactions. "
    },
    {
      "path": "/build/d/sdk/chunked-uploader/connecting",
      "content": " Sample code for connecting to a node ;Connecting When using the chunking uploader, first create an Irys object and then follow that by requesting the chunked uploader using irys.uploader.chunkedUploader.The chunkedUploader object reference must be updated before each subsequent upload, it can not be reused.let irys = await getIrysUploader(); let uploader = irys.uploader.chunkedUploader;Use a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here. "
    },
    {
      "path": "/build/d/sdk/chunked-uploader/controlling-the-upload",
      "content": " Pausing and resuming uploads ;Controlling the upload Uploads created with the chunked uploader can be paused and resumed at any time using the functions uploader.pause() and uploader.resume(). For these functions to work, the initial call to uploader.uploadData() or uploader.uploadTransaction() must not be preceded with the await keyword. To resume an upload from a new uploader instance, you must use the same: Token Network (testnet) Input data Configured chunk sizeuploader.pause() and uploader.resume()Use a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); // When uploading smaller files, it's common to use the await keyword before // uploadData() or uploadTransaction(). This causes execution to pause until the file // is fully uploaded. If you omit await, the upload happens in the background // and you can use pause and resume as needed. transaction = irys.createTransaction(\"Hello, world!\"); uploader = irys.uploader.chunkedUploader; // Recreate for each transaction const upload = uploader.uploadTransaction(transaction); uploader.pause(); // Pauses the upload console.log(\"Upload paused\"); uploader.resume(); // Resumes the upload console.log(\"Upload resumed\"); While the initial call to uploader.uploadData() or uploader.uploadTransaction() should not use the await keyword, you can use it down the line to ensure the upload is complete. You can call await at ANY TIME to ensure the upload has is complete. response = await upload; `"
    },
    {
      "path": "/build/d/sdk/chunked-uploader/data-mode",
      "content": " Automate transaction creation in Data ModeData Mode The chunked uploader has two modes of operation, Data Mode and Transaction Mode. When using data mode do not create a transaction, this will be done automatically for you. Within Data Mode, you can either upload using: A buffer containing the data you want to upload. A readable stream pointing to the data you want to upload.uploader.uploadData() const transactionOptions = { tags: [{ name: \"Content-Type\", value: \"text/plain\" }] }; // 1. Upload a Buffer containing just the data you want to upload. const dataBuffer = Buffer.from(\"Hirys, world!\"); const response = await uploader.uploadData(dataBuffer, transactionOptions); // The transaction ID (used to query the network) is found in response.data.id console.log(Data buffer uploaded ==> https://gateway.irys.xyz/${response.data.id}); // 2. OR Upload a Readable (stream) pointing to the data uploader = irys.uploader.chunkedUploader; // Recreate for each transaction const dataStream = fs.createReadStream(\"./data.txt\"); response = await uploader.uploadData(dataStream, transactionOptions); console.log(Read Stream uploaded ==> https://gateway.irys.xyz/${response.data.id}); `"
    },
    {
      "path": "/build/d/sdk/chunked-uploader/expired-uploads",
      "content": " Recovering expired uploadsExpired uploads Paused uploads will expire after a period of inactivity. If you need to recover an expired upload, use the following: const resumeData = uploader.getResumeData(); uploader.setResumeData(resumeData); await uploader.uploadTransaction(dataItem); `"
    },
    {
      "path": "/build/d/sdk/chunked-uploader/setting-upload-parameters",
      "content": " Changing batch and chunk sizeSetting upload parameterssetBatchSize() and uploader.setUploadSize() The default batch size (number of chunks to upload at once) is 5, the default chunk size (maximum chunk size) is 25MB. These values can be changed using the functions uploader.setBatchSize(size) and uploader.setUploadSize(size). uploader.setBatchSize(10); // Value is in bytes uploader.setChunkSize(500000); `"
    },
    {
      "path": "/build/d/sdk/chunked-uploader/transaction-mode",
      "content": " Access fine-grained control over transactionsTransaction Mode Transaction Mode gives you more fine-grained control over the upload workflow. You can create and sign your transaction first, store it, and then upload when it makes the most sense for your application.uploadTransaction() uploader = irys.uploader.chunkedUploader; // Recreate for each transaction const transaction = irys.createTransaction(\"Hello, world!\"); await transaction.sign(); response = await uploader.uploadTransaction(transaction); console.log(Transaction mode uploaded ==> https://gateway.irys.xyz/${response.data.id}); `"
    },
    {
      "path": "/build/d/sdk/chunked-uploader/upload-events",
      "content": " Track upload progress with event callbacksUpload events The uploader emits three events during each upload. These can be subscribed to for any use case when tracking upload progress is needed. chunkUpload: Emitted whenever a chunk is uploaded. chunkError: Emitted whenever a chunk upload fails. Due to internal retry logic, these errors can most likely be ignored as long as the upload doesn't error overall. done: Emitted when the upload completes. uploader.on(\"chunkUpload\", (chunkInfo) => {console.log(Uploaded Chunk number ${chunkInfo.id}, offset of ${chunkInfo.offset}, size ${chunkInfo.size} Bytes, with a total of ${chunkInfo.totalUploaded} bytes uploaded.,); }); uploader.on(\"chunkError\", (e) => {console.error(Error uploading chunk number ${e.id} - ${e.res.statusText}); }); uploader.on(\"done\", (finishRes) => {console.log(Upload completed with ID ${finishRes.id}); }); `"
    },
    {
      "path": "/build/d/sdk/chunked-uploader",
      "content": " A fault-tolerant, resumable, signer & uploader ;Chunked Uploader The Chunked Uploader is a fault-tolerant, resumable, stream-based signer and uploader. It allows you to pause and resume uploads, and to do things like create progress bars that show upload progress. Key Terminology: Batch size:the maximum number of chunks to upload at once. Defaults to 5. Chunk size: the maximum size of a single chunk. Defaults to 25MB. For those with slower/unstable connections, reducing both should lead to improved reliability. For those with faster connections, increasing both will lead to higher throughput, at the cost of more memory (and CPU).The default uploder (accessed via irys.upload()) does chunking automatically. You only need to use the ChunkedUploader to access advanced features like pausing and resuming uploads, changing batch size, and changing chunk size. "
    },
    {
      "path": "/build/d/sdk/payment/fund",
      "content": " Funds the node with the specified amount of tokens ; ;fund(amount, multiplier?) Funds your account with the specified number of tokens.Parameters Returnsresponse = {id, // The transaction ID of the fund transferquantity, // How much is being transferredreward, // The amount taken by the network as a feetarget, // The address the funds were sent to }; You can choose to upfront fund where you cover the cost of future uploads, or use lazy-funding where you fund per-upload.Upfront Funding Upfront funding reduces the number of transactions required when uploading. You fund once and then when uploading, payment is deducted directly from your account. You can also withdraw any excess balance if needed.Use a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.try {const irys = await getIrysUploader();const fundTx = await irys.fund(irys.utils.toAtomic(0.05));console.log(`Successfully funded ${irys.utils.fromAtomic(fundTx.quantity)} ${irys.token}`); } catch (e) {console.log(\"Error funding node \", e); }Lazy-Funding try {const irys = await getIrysUploader();const pathToFile = \"./myNFT.png\";const { size } = await fs.promises.stat(pathToFile);const price = await irys.getPrice(size);await irys.fund(price);const { id } = await irys.uploadFile(pathToFile);console.log(${pathToFile} --> Uploaded to https://gateway.irys.xyz/${id}); } catch (e) {console.log(\"Error funding node \", e); }Lazy-funding works best when using blockchains like Ethereum and Solana wheretransactions are finalized quickly. Fee Multiplier The multiplier parameter multiplies the fees we allow the network to take, in effect prioritizing the transaction. Normally you can safely ignore this parameter, however, if you're experiencing errors when funding, you can try passing a value of 1.2 or more. try {const irys = await getIrysUploader();const fundTx = await irys.fund(irys.utils.toAtomic(0.05), 1.2);console.log(`Successfully funded ${irys.utils.fromAtomic(fundTx.quantity)} ${irys.token}`); } catch (e) {console.log(\"Error funding node \", e); }Paid RPCs When transferring tokens we use public RPCs. Sometimes these can be slow to confirm transactions. If you're experiencing an error when funding, consider using a paid RPC. ; const getIrysUploader = async () => {const rpcUrl = \"\";const irysUploader = await Uploader(Ethereum).withWallet(process.env.PRIVATE_KEY).withRpc(rpcUrl);return irysUploader; }; `"
    },
    {
      "path": "/build/d/sdk/payment/funder-submitFundTransaction",
      "content": " Returns the receipt associated with the supplied transaction id ; ;funder.submitFundTransaction() Tells the network to re-evaluate a funding transaction.Parameters Returnsresponse = {id, // The transaction ID of the fund transferquantity, // How much is being transferredreward, // The amount taken by the network as a feetarget, // The address the funds were sent to };ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); try {// First get a receiptconst fundTx = await irys.fund(irys.utils.toAtomic(0.05));const response = await irys.funder.submitFundTransaction(fundTx.id); } catch (e) {console.log(\"Error funding \", e); } `"
    },
    {
      "path": "/build/d/sdk/payment/getBalance",
      "content": " Returns the connected wallet's balance. ; ;getBalance() Returns the connected wallet's balance.Returns ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); // Get loaded balance in atomic units const atomicBalance = await irys.getBalance(); console.log(Node balance (atomic units) = ${atomicBalance}); // Convert balance to standard const convertedBalance = irys.utils.fromAtomic(atomicBalance); console.log(Node balance (converted) = ${convertedBalance}); `"
    },
    {
      "path": "/build/d/sdk/payment/getPrice",
      "content": " Returns the cost to upload the specified number of bytes ; ;getPrice(numBytes) Returns the cost to upload the specified number of bytes.Parameters Returns ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); const numBytes = 1048576; // Number of bytes to check const priceAtomic = await irys.getPrice(numBytes); // Convert from atomic units to standard units const priceConverted = irys.utils.fromAtomic(priceAtomic); console.log(Uploading ${numBytes} bytes costs ${priceConverted}); `"
    },
    {
      "path": "/build/d/sdk/payment/withdrawAll",
      "content": " Withdraws the supplied amount ; ;withdrawAll() Withdraws the the user's entire account balance. The unit is the token parameter supplied when creating the Irys object. If you have balances in more than one token, you must re-instantiate the Irys object for each token.Returns400 - something went wrong 200 - Ok response.data = {requested, // the requested amount,fee, // the reward required by the network (network fee)final, // total cost to your account (requested + fee)tx-id, // the ID of the withdrawal transaction }ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.try {const irys = await getIrysUploader();const tx = await irys.withdrawAll(); } catch (e) {console.log(\"Error withdrawing funds \", e); } `"
    },
    {
      "path": "/build/d/sdk/payment/withdrawBalance",
      "content": " Withdraws the supplied amount ; ;withdrawBalance(amount) Withdraws the specified amount from the user's account balance. The unit is the token parameter supplied when creating the Irys object. If you have balances in more than one token, you must re-instantiate the Irys object for each token.Parameters Returns400 - something went wrong response.data = \"Not enough balance for requested withdrawal\" 200 - Ok response.data = {requested, // the requested amount,fee, // the reward required by the network (network fee)final, // total cost to your account (requested + fee)tx-id, // the ID of the withdrawal transaction }ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); try {// 1. Get current balanceconst curBalance = await irys.getLoadedBalance();// 2. Withdraw allconst response = await irys.withdrawBalance(curBalance);console.log(Successfully withdrew ${irys.utils.fromAtomic(curBalance)} ${irys.token}); } catch (e) {console.log(\"Error uploading data \", e); } `"
    },
    {
      "path": "/build/d/sdk/setup",
      "content": " Importing and configuring the SDK ;Installing, Importing & Configuring The Irys SDK reduces dependency bloat by providing dedicated packages for each token. Your install statements, import and connection code will differ depending on the token used for payment. Select the appropriate code from the options below when starting your project.APTOS |Arbitrum | Avalanche C-Chain | Berachain | BNB | Chainlink | Eclipse-eth | Ethereum | Base Ethereum | Linea Ethereum | Scroll Ethereum | IoTeX | Polygon | Solana | USDC (on Ethereum) | USDC (on Polygon)The following code examples connect to our alpha testnet. To switch to our devnet, append the functions withRpc() and devnet() as outlined here. Aptos Installing: npm install @irys/upload @irys/upload-aptos Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Aptos).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Arbitrum Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Arbitrum).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Avalanche C-Chain Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Avalanche).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Berachain Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Bera).withWallet(process.env.PRIVATE_KEY);return irysUploader; };BNB Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(BNB).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Chainlink Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Chainlink).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Eclipse-eth Installing: npm install @irys/upload @irys/upload-solana Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(EclipseEth).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Ethereum Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Ethereum).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Base Ethereum Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(BaseEth).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Linea Ethereum Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(LineaEth).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Scroll Ethereum Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(ScrollEth).withWallet(process.env.PRIVATE_KEY);return irysUploader; };IoTeX Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Iotex).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Polygon Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Matic).withWallet(process.env.PRIVATE_KEY);return irysUploader; };Solana Installing: npm install @irys/upload @irys/upload-solana Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(Solana).withWallet(process.env.PRIVATE_KEY);return irysUploader; };USDC (on Ethereum) Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(USDCEth).withWallet(process.env.PRIVATE_KEY);return irysUploader; };USDC (on Polygon) Installing: npm install @irys/upload @irys/upload-ethereum Importing & Configuring: ; ; const getIrysUploader = async () => {const irysUploader = await Uploader(USDCPolygon).withWallet(process.env.PRIVATE_KEY);return irysUploader; }; `"
    },
    {
      "path": "/build/d/sdk/upload/upload",
      "content": " Uploads data ; ;upload(data, tags?, anchor?) Uploads data to Irys.Parameters Returnsresponse = {id, // Transaction ID (used to download the data)timestamp, // Timestamp (UNIX milliseconds) of when the transaction was created and verifiedversion, // The version of this JSON file, currently 1.0.0public, // Public key of the bundler node usedsignature, // A signed deep hash of the JSON receiptdeadlineHeight, // The block number by which the transaction must be finalizedblock, // DeprecatedvalidatorSignatures, // Deprecatedverify, // An async function used to verify the receipt at any time }Funding Uploads of less than 100 KiB are are free. For larger uploads, you'll need to fund your account first.ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); const dataToUpload = \"Hirys world.\"; try {const receipt = await irys.upload(dataToUpload);console.log(Data uploaded ==> https://gateway.irys.xyz/${receipt.id}); } catch (e) {console.log(\"Error uploading data \", e); }Use the transaction ID returned as part of the response to download the data by creating a URL in the formathttps://gateway.irys.xyz/:transactionId. "
    },
    {
      "path": "/build/d/sdk/upload/uploadFile",
      "content": " Uploads a file ; ;uploadFile(fileName, tags?) Uploads a file to Irys.Parameters Returnsresponse = {id, // Transaction ID (used to download the data)timestamp, // Timestamp (UNIX milliseconds) of when the transaction was created and verifiedversion, // The version of this JSON file, currently 1.0.0public, // Public key of the bundler node usedsignature, // A signed deep hash of the JSON receiptdeadlineHeight, // The block number by which the transaction must be finalizedblock, // DeprecatedvalidatorSignatures, // Deprecatedverify, // An async function used to verify the receipt at any time }Funding Uploads of less than 100 KiB are are free. For larger uploads, you'll need to fund your account first.ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); // Your file const fileToUpload = \"./myImage.png\"; // Add a custom tag that tells the gateway how to serve this file to a browser const tags = [{ name: \"Content-Type\", value: \"image/png\" }]; try {const response = await irys.uploadFile(fileToUpload, tags);console.log(File uploaded ==> https://gateway.irys.xyz/${response.id}); } catch (e) {console.log(\"Error uploading file \", e); }Use the transaction ID returned as part of the response to download the data by creating a URL in the formathttps://gateway.irys.xyz/:transactionId. "
    },
    {
      "path": "/build/d/sdk/upload/uploadFolder",
      "content": " Uploads a folder of files to Irys ; ;uploadFolder() Uploads a group of files to Irys in a single transaction. See: NodeJS: For uploading a folder on the server. Browser: For uploading a folder from the browser.Funding Uploads of less than 100 KiB are are free. For larger uploads, you'll need to fund your account first.NodeJSParameters Returns{id, // Transaction ID (used to download the data)timestamp, // Timestamp (UNIX milliseconds) of when the transaction was created and verifiedversion, // The version of this JSON file, currently 1.0.0public, // Public key of the bundler node usedsignature, // A signed deep hash of the JSON receiptdeadlineHeight, // The block number by which the transaction must be finalizedblock, // DeprecatedvalidatorSignatures, // Deprecatedverify, // An async function used to verify the receipt at any time }ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); // Upload an entire folder const folderToUpload = \"./my-images/\"; // Path to folder try {const response = await irys.uploadFolder(\"./\" + folderToUpload, {indexFile: \"\", // Optional index file (file the user will load when accessing the manifest)batchSize: 50, // Number of items to upload at oncekeepDeleted: false, // Whether to keep now deleted items from previous uploads});console.log(Files uploaded. Manifest ID ${response.id}); } catch (e) {console.log(\"Error uploading file \", e); }Browser Pass an array of File objects.Parameters Returns{id, // Manifest IDtimestamp, // Timestamp (UNIX milliseconds) of when the transaction was created and verifiedversion, // The version of this JSON file, currently 1.0.0public, // Public key of the bundler node usedsignature, // A signed deep hash of the JSON receiptdeadlineHeight, // The block number by which the transaction must be finalizedblock, // DeprecatedvalidatorSignatures, // Deprecatedverify, // An async function used to verify the receipt at any time }Example const irysUploader = await getIrysUploader(); const files: File[] = []; const tags: { name: string; value: string } = []; // Set files and tags in your UI // Convert to TaggedFile objects const taggedFiles = files.map((f: TaggedFile, i: number) => {f.tags = tags[i];return f; }); // Optional parameters const uploadOptions = {indexFileRelPath: \"./index.html\",manifestTags: myTags,throwawayKey: myKey,seperateManifestTx: true, }; const response = await irysUploader.uploadFolder(taggedFiles, uploadOptions);Returns A JSON object containing the following values. A receipt is also generated which can be retrieved using irys.utils.getReceipt(response.id) {id, // Transaction IDmanifestId, // Manifest IDmanifest, // The manifesttxs, // An array of DataItems, one for each entry in the bundletimestamp, // Timestamp (UNIX milliseconds) of when the transaction was created and verifiedversion, // The version of this JSON file, currently 1.0.0public, // Public key of the bundler node usedsignature, // A signed deep hash of the JSON receiptdeadlineHeight, // The block number by which the transaction must be finalizedblock, // DeprecatedvalidatorSignatures, // Deprecatedverify, // An async function used to verify the receipt at any time }Downloading Files uploaded via uploadFolder() can be retrieved in one of two ways. Creating a URL with the format https://gateway.irys.xyz/:manifestId/:originalFileName. Creating a URL using the transaction ID of each individual file uploaded with the format https://gateway.irys.xyz/:transactonId After a successful folder upload, two files are written to your local project directory [foldername].csv and [foldername].json. The example below highlights a folder called with a total of 5 files in it. The transaction ID for each file can be used to retrieve the uploaded data by forming a URL with the format https://gateway.irys.xyz]/:transactionId "
    },
    {
      "path": "/build/d/sdk/upload/uploader-uploadBundle",
      "content": " Uploads an array of transactions as a bundle ; ;upload.uploadBundle(tx, bundleOptions?) Uploads an array of transactions as a bundle in a single transaction. This function is provided for users who need to obtain each transaction's ID before uploading. However, most users will use uploadFolder(), an abstraction that handles the uploading, signing and bundling in a single function call.Parameters Notes If a provided transaction is unsigned, the transaction is signed using a temporary (throwaway) key. This means transactions can be associated with a single \"random\" address. If a buffer is provided, it is converted into a transaction and then signed by the throwaway key. The throwaway key, address, and all bundled (provided + throwaway signed + generated) transactions are returned by this method.Returnsresponse = {id, // Transaction ID (used to download the data)timestamp, // Timestamp (UNIX milliseconds) of when the transaction was created and verifiedversion, // The version of this JSON file, currently 1.0.0public, // Public key of the bundler node usedsignature, // A signed deep hash of the JSON receiptdeadlineHeight, // The block number by which the transaction must be finalizedblock, // DeprecatedvalidatorSignatures, // Deprecatedverify, // An async function used to verify the receipt at any time }Funding Uploads of less than 100 KiB are are free. For larger uploads, you'll need to fund your account first.Tags You can add an optional array of tags in the BundleOptions object (see code example below)ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const uploadBundle = async () => {const irys = await getIrysUploader();const maxTxs = 5;const txs = [];// First create and sign a group of transactionsfor (let i = 0; iThe transaction ID returned as part of the response is used to download the data, simply create a URL with the formathttps://gateway.irys.xyz/:transactionId. "
    },
    {
      "path": "/build/d/sdk/utils/utils-fromAtomic",
      "content": " Converts from atomic to standard units ; ;utils.fromAtomic(value) Converts from atomic to standard units.Parameters Returns ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); const atomicBalance = await irys.getLoadedBalance(); const convertedBalance = irys.utils.fromAtomic(atomicBalance).toString();Atomic units refer to the smallest possible unit of a given cryptocurrency. In Ethereum, atomic units are calledWei, and they represent the smallest unit of Ether. Similar to how 1 dollar can be broken down into 100 cents, 1Ether can be broken down into 10^18 Wei. In Solana, atomic units are called Lamports, 1 SOL can be broken down into10^9 Lamports. "
    },
    {
      "path": "/build/d/sdk/utils/utils-getReceipt",
      "content": " Returns the receipt associated with the supplied transaction ID ; ;utils.getReceipt(transactionId) Returns the receipt associated with the supplied transaction ID, or an error if no receipt is found.Parameters Returnsresponse = {id, // Transaction ID (used to download the data)timestamp, // Timestamp (UNIX milliseconds) of when the transaction was created and verifiedversion, // The version of this JSON file, currently 1.0.0public, // Public key of the bundler node usedsignature, // A signed deep hash of the JSON receiptdeadlineHeight, // The block number by which the transaction must be finalizedblock, // DeprecatedvalidatorSignatures, // Deprecatedverify, // An async function used to verify the receipt at any time }Example const irys = await getIrysUploader(); try {const transactionID = \"i9tgbHsr6c1sxryAQ-SLM2rfQAYRuyap7RmGgH28mI4\"; // Your transaction IDconst receipt = await irys.utils.getReceipt(transactionID);console.log(receipt); } catch (e) {console.log(\"Error getting receipt \", e); } `"
    },
    {
      "path": "/build/d/sdk/utils/utils-toAtomic",
      "content": " Converts from standard to atomic units ; ;utils.toAtomic(value) Converts from standard to atomic units.Parameters Returns ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); const amountAtomic = irys.utils.toAtomic(amountStandard);Atomic units refer to the smallest possible unit of a given cryptocurrency. In Ethereum, atomic units are calledWei, and they represent the smallest unit of Ether. Similar to how 1 dollar can be broken down into 100 cents, 1Ether can be broken down into 10^18 Wei. In Solana, atomic units are called Lamports, 1 SOL can be broken down into10^9 Lamports. "
    },
    {
      "path": "/build/d/sdk/utils/utils-verifyReceipt",
      "content": " Returns the receipt associated with the supplied transaction id ; ;utils.verifyReceipt(receipt) Returns true or false, indicating if a receipt is valid or not.Parameters{id, // Transaction IDpublic, // Public key of the bundler node usedsignature, // A signed deep hash of the JSON receiptdeadlineHeight, // The block number by which the transaction must be finalizedtimestamp, // Timestamp (UNIX milliseconds) of when the transaction was created and verifiedversion, // The version of this JSON file, currently 1.0.0 }Returns ExampleUse a token-specific version of getIrysUploader() to connect to an Irys Bundler before uploading. Choose one from here.const irys = await getIrysUploader(); try {// First get a receiptconst transactionID = \"i9tgbHsr6c1sxryAQ-SLM2rfQAYRuyap7RmGgH28mI4\"; // Your transaction Idconst receipt = await irys.utils.getReceipt(transactionID);// Then verify itconst isReceiptValid = await irys.utils.verifyReceipt(receipt);console.log(isReceiptValid); } catch (e) {console.log(\"Error getting receipt \", e); } `"
    },
    {
      "path": "/build/d/storage-cli/commands/balance",
      "content": " Funds the node with the specified amount of tokens. ; ;balance Returns the amount of funds available on the specified node. Provide your public wallet address as an argument, along with:Parameters ExamplesTestnet irys balance 0x591B5Ce7cA10a55A9B5d1516eF89693D5b3586b8 \\-t ethereumDevnet irys balance 0x591B5Ce7cA10a55A9B5d1516eF89693D5b3586b8 \\-t ethereum \\-n devnet \\--provider-url https://rpc.sepolia.devRPC URLs change often, use a recent one from https://chainlist.org/ "
    },
    {
      "path": "/build/d/storage-cli/commands/fund",
      "content": " Funds the node with the specified amount of tokens. ; ;fund Fund Irys with the specified amount of tokens.Not all calls to fund will post immediately to your account, some blockchains are faster than others. Parameters ExamplesTestnet irys fund 1000000000000000 \\-t ethereum \\-w bf20......c9885307Devnet irys fund 1000000000000000 \\-n devnet \\-t ethereum \\-w bf20......c9885307 \\--provider-url https://rpc.sepolia.devRPC URLs change often, use a recent one from https://chainlist.org/ "
    },
    {
      "path": "/build/d/storage-cli/commands/price",
      "content": " Funds the node with the specified amount of tokens. ; ;price Checks the price to upload the specified number of bytes.Parameters ExamplesTestnet irys price 1000000 \\-t ethereumDevnet irys price 1000000 \\-t ethereum \\-n devnet \\--provider-url https://rpc.sepolia.devRPC URLs change often, use a recent one from https://chainlist.org/ "
    },
    {
      "path": "/build/d/storage-cli/commands/upload-dir",
      "content": " Funds the node with the specified amount of tokens. ; ;upload-dir Uploads an entire directory of files.Parameters ExamplesTestnet irys upload-dir ./myImages \\-t ethereum \\-w bf20......c9885307Devnet irys upload-dir ./myImages \\-n devnet \\-t ethereum \\-w bf20......c9885307 \\--provider-url https://rpc.sepolia.devRPC URLs change often, use a recent one from https://chainlist.org/ Downloading Files uploaded via irys upload-dir can be retrieved in one of two ways. Creating a URL with the format https://gateway.irys.xyz/manifestId/:originalFileName]. Creating a URL using the transaction ID of each individual file uploaded with the format https://gateway.irys.xyz/:transactonId After a successful folder upload, two files are written to your local project directory: [folder_name].csv [folder_name].json The example below highlights a folder called with a total of 5 files in it. The transaction ID for each file can be used to retrieve the uploaded data by forming a URL with the format https://gateway.irys.xyz]/transactionId "
    },
    {
      "path": "/build/d/storage-cli/commands/upload",
      "content": " Funds the node with the specified amount of tokens. ; ;upload Uploads a single file.Parameters`.\" },{ type: \"--provider-url\", \"RPC URL to use.\" }, ]}/>ExamplesTestnet irys upload myImage.png \\-t ethereum \\-w bf20......c9885307 \\--tags tagName1 tagValue1 tagName2 tagValue2Devnet irys upload myImage.png \\-n devnet \\-t ethereum \\-w bf20......c9885307 \\--tags tagName1 tagValue1 tagName2 tagValue2 \\--provider-url https://rpc.sepolia.devRPC URLs change often, use a recent one from https://chainlist.org/ Downloading Files uploaded via irys upload can be downloaded using the transaction ID provided after a successful upload. irys upload myImage.png \\-n testnet \\-t aptos \\-w bf20......c9885307 \\--tags tagName1 tagValue1 tagName2 tagValue2 Loaded address: 0xac568a981b1370b2e1baa8ce30bd5ac9e28c572d Uploaded to https://gateway.irys.xyz/yPX6rwxfJ2gTvXSHGoumIvlFR-EwuRlUMmHpeLHUM `"
    },
    {
      "path": "/build/d/storage-cli/commands/withdraw",
      "content": " Funds the node with the specified amount of tokens. ; ;withdraw Withdraws funds from Irys.Not all calls to withdraw will post immediately to your account, some blockchains are faster than others. Parameters ExamplesTestnet irys withdraw 1000000000000000 \\-t ethereum \\-w bf20......c9885307Devnet irys withdraw 1000000000000000 \\-n testnet \\-t ethereum \\-w bf20......c9885307 \\--provider-url https://rpc.sepolia.devRPC URLs change often, use a recent one from https://chainlist.org/ "
    },
    {
      "path": "/build/d/storage-cli/installation",
      "content": " Install the CLI. ;Installation Install using npm with the -g global flag. npm i -g @irys/cli Depending on your setup, you may need to use the sudo command. sudo npm i -g @irys/cliIf you get an error while installing, append the --force flag to the end of the above command. "
    },
    {
      "path": "/build/d/troubleshooting",
      "content": " Troubleshooting common problemsTroubleshooting Troubleshooting common errors during installation and use. Errors: bigint: Failed to load bindings, pure JS will be used (try npm run rebuild?) Error: Not enough balance for transaction Error: Transaction simulation failed: Blockhash not foundbigint Error message: bigint: Failed to load bindings, pure JS will be used (try npm run rebuild?) This error can be safely ignored, it will not cause any issues. To make the error go away, you'll need to install updated Python and C++ build tools. MacOS Current versions of MacOS come pre-built with Python. To install the C++ build tools: First install XCode Once XCode is installed, go to Preferences, Downloads, and install the Command Line Tools Windows Windows users need to install both Python and C++ build tools. These commands must be run with administrator permissions. // First run: npm i -g --add-python-to-path --vs2015 --production windows-build-tools // Then run: npm i -g node-gyp@latest UNIX Most UNIX distributions come with Python installed. To install C++ build tools, the following works for most Debian-based systems. For others, use your package manager to install \"GCC build tools\". sudo apt-get install build-essentialInsufficient Balance Error message: Error: Not enough balance for transaction This error occurs when you try to upload to a node without first funding it. Tokens for use on our testnet can be obtained for free from common faucets like the ones for Solana and Sepolia.Blockhash Not Found Error message: Error: Transaction simulation failed: Blockhash not found Irys depends on transactions being confirmed, however, in some situations, it may be necessary to wait for the transaction to be finalized. This can be fixed by configuring Irys as follows: const irys = new Irys({url: nodeUrl,token,provider,config: { tokenOpts: { commitment: \"finalized\" } }, }); `"
    },
    {
      "path": "/build/programmability/connecting-to-testnet",
      "content": "Connecting to the testnetNetwork RPC Node: testnet-rpc.irys.xyz Wallet: wallet.irys.xyz Explorer: testnet-explorer.irys.xyz The chain is EVM compatible so you can use all standard EVM tooling including Metamask. The network also has custom endpoints for all datachain related activity.Chain info Ticker: IRYS Atomic unit: mIRYS (mini IRYS) Decimals: 18 Chain ID: 1270 EVM compatible JSON-RPC URL: https://testnet-rpc.irys.xyz/v1/execution-rpcConnecting with Ethers const irysClient = await new IrysClient(\"https://testnet-rpc.irys.xyz/v1\") const provider = irysClient.api.rpcProvider // or const provider = new JsonRpcProvider(\"https://testnet-rpc.irys.xyz/v1/execution-rpc\") const balance = await provider.getBalance(\"\") `"
    },
    {
      "path": "/build/programmability/introduction",
      "content": "Our alpha testnet is live! With our testnet live you can store data directly on the L1, build apps with IrysVM and Programmable DataIrysVM As a fork of the Ethereum Virtual Machine (EVM), the Irys Virtual Machine (IrysVM) leverages the unique capabilities of the Irys blockchain by integrating access to its advanced storage layer, unlocking the potential for Programmable Data.Programmable Data Programmable Irys unlocks a new paradigm where data can be actively used and manipulated in real-time by smart contracts. With Programmable Data, Irys integrates cost-effective data storage and smart-contract functionality, enabling dApps and services to interact programmatically with large amounts of onchain data within a single protocol and ecosystem. This streamlines development, lowers costs, and unlocks unprecedented composability, overcoming the limitations of fragmented integrations. {/* ## Ledgers Ledgers are a key data model innovation, allowing for scalable configurable duration storage. the Irys testnet currently has 2 ledgers: 0: the Perm ledger - This is for data that is stored permanently. 1: the Term ledger - This is for data upload validation for Perm txs. It has a minimum storage duration of 5 days. For a more complete break down, see Learn: Ledgers */}"
    },
    {
      "path": "/build/programmability/js/addresses",
      "content": "Addresses Irys uses two address formats, one base58 encoded (i.e 2QZrWyPPi4XukwiJQrVmUvuPQ57F) known as the Irys address, and one hex encoded (i.e 0x64f1a2829e0e698c18e7792d6e74f67d89aa0a32), the Execution address - which is a traditional EVM address.\\ Both address types are cross-convertable, with the execution address being a hex encoding of the decoded Irys address bytes.\\ @irys/js has some conversion utilities you can use: const irysAddress = \"2QZrWyPPi4XukwiJQrVmUvuPQ57F\"; const execAddress = \"0x64f1a2829e0e698c18e7792d6e74f67d89aa0a32\" irysToExecAddr(irysAddress) //\"0x64f1a2829e0e698c18e7792d6e74f67d89aa0a32\" execToIrysAddr(execAddress) //\"2QZrWyPPi4XukwiJQrVmUvuPQ57F\" Irys & execution addresses are derived using the same private key, so your Irys execution address will be identical to your usual EVM one."
    },
    {
      "path": "/build/programmability/js/quickstart",
      "content": ";Quickstart This covers how to make use of Irys's @irys/js package, but you can also use all EVM compatible tooling for developing apps on Irys.Install yarn install @irys/jsGrab some tokens! The testnet faucet can be found hereCreate the client const irysClient = await new IrysClient(\"https://testnet-rpc.irys.xyz/v1\") Get your Irys addressIrys uses the same private keys as Ethereumconst { irys: irysAddress } = irysClient.account.getAddresses(\"private key\") For more information about addresses, see AddressesCheck your balance const balancemIrys = await irysClient.account.getBalance(\"address\") // you can use either your Irys or execution address! This gets your balance in mIrys (mini-irys), which you can think of as our version of weiCreate and post a data transaction // Create a transaction const tx = irysClient.createTransaction({...}) // the args are optional // Generates merkle tree for the data await tx.prepareChunks(); // Check the price (in mIrys) for uploading your transaction. // Irys transactions have two fees, a term and a perm fee. // perm is only for if you want to store your data permanently (i.e ledger 0) // Testnet currently only supports perm transactions. const { termFee, permFee } = await tx.getFees(); // get the combined fee const fee = await tx.getFee(); // Sign the transaction with your private key const signedTx = await tx.sign(); // Upload the transaction header await signedTx.uploadHeader(); // Upload the data await signedTx.uploadChunks(); `"
    },
    {
      "path": "/build/programmability/programmable-data",
      "content": ";Programmable data quickstartThis guide assumes you're decently familiar with solidity smart contract development. Create a programmable data smart contract Programmable data is a feature leveraged through Solidity smart contracts via a custom precompile.\\ We have a library contract to provide a cleaner API to use programmable data here A full example Foundry project here And an example E2E test using @irys/js here To use this library, first create a Solidity contract that inherits ProgrammableData: // SPDX-License-Identifier: MIT pragma solidity ^0.8.20; // you will need to set up path remapping and clone the repository as a submodule, // or copy the library files locally import \"@irys/precompile-libraries/libraries/ProgrammableData.sol\"; contract ProgrammableDataBasic is ProgrammableData {bytes public storedData;function readPdBytesIntoStorage() public {(bool success, bytes memory data) = readBytes();require(success, \"reading bytes failed\");// write bytes to storagestoredData = data;}function getStorage() public view returns (bytes memory) {return storedData;} } You then need to deploy your smart contract as normal. To create a programmable data transaction (which will allow use of the ProgrammableData precompile), follow the following steps:Create a set of Programmable Data read ranges const accessList = await irysClient.programmable_data.read(transactionId, startOffset, length).toAccessList(); This range will read bytes startOffset -> startOffset + length of transactionId's data.Only transactions uploaded to the permanent ledger (ledgerId 0) can be read using programmable data.\\DataItems uploaded through Irys' bundlers are currently not supported (but will be!) Add them to a execution Transaction This should be a transaction aiming to call the readPdBytesIntoStorage method of the contract.You will be charged for every chunk you request, even if you don't read them.\\So only attach a programmable data access list to a transaction that will use them!;const wallet = new Wallet(, irysClient.api.rpcProvider)const evmTransaction = {accessList: [accessList],type: 2 // type must be EIP-1559 or higher....}await wallet.sendTransaction(evmTransaction); Once the transaction processes, you can call the getStorage contract method, which should return the data you specified in your programmable data read range.\\ Note that you will pay normal rates for storing data in smart contract storage slots."
    },
    {
      "path": "/build/welcome-builders",
      "content": " Welcome to the Irys alpha testnetA Note From Our Founder:\"Hirys, and welcome to our alpha testnet— you're dangerously early.\" If you're wondering who we are, let me fill you in. We're Irys, the world's first programmable datachain. Datachain means we're an L1 that incentivizes storage. Programmable means that data on Irys is composable. On Irys, smart contracts will be able to natively access (read), manipulate (validate, reference, or evolve), and write back to the storage layer (output)—all within a single protocol. Our alpha testnet is live as of September 2nd, 2024, starting with support for permanent data uploads. Over the coming weeks, we'll be rolling out the IrysVM, temporary data, and programmable data.\"PS: If you have any questions, hit us up in Discord."
    },
    {
      "path": "/learn/build-with-us",
      "content": " Build With Us Join Irys, the first L1 programmable datachain. Be an early pioneer, shape the future, and collaborate with like-minded developers. Stay tuned for updates and share your feedback.Build With Us (Coming Soon!) We are excited to announce that Irys is currently under development, and we’re eager to have you join us on this journey. Our goal is to create the most innovative and user-friendly datachain platform, and we need your feedback to make it happen.Why Join Us? Be an Early Pioneer: Get early access to our platform and be among the first to build with Irys. Shape the Future: Your feedback is invaluable in helping us improve and refine our technology. Collaborate and Innovate: Work with a community of like-minded developers and enthusiasts to push the boundaries of what’s possible.Stay Tuned! More information and updates will be available soon. In the meantime, we would love to hear your thoughts and ideas. Together, we can create something amazing.Contact Us Have suggestions or want to get involved? Reach out to us on: Telegram Discord Twitter Let’s build the future of decentralized applications with Irys!"
    },
    {
      "path": "/learn/network-overview/becoming-a-miner-on-irys",
      "content": " Irys miners validate, replicate, and secure storage while earning rewards, ensuring decentralized scalability and reliability.Becoming a Miner on Irys Miners on Irys do more than just solve computations; they stake resources and pledge specific data partitions, integrating a Proof of Work (PoW) / Proof of Stake consensus model to create a network built on integrity and accountability. This dual-layer commitment—both computational and economic—reinforces network reliability and deters malicious behavior.Mining RequirementsSystem Requirements CPU: A fast core with SHA-256 extensions is recommended to handle the Verifiable Delay Function (VDF). Storage: Each partition requires 16TB, with enterprise-grade HDDs providing the necessary durability and performance. GPU for Packing: A modern gaming GPU can accelerate the Matrix Packing process by dividing tasks across multiple processors, helping prepare data for verification quickly. Minimum system requirements will be established based on performance observed during testnet.Consensus Model Irys uses a consensus model that combines Proof of Work with Proof of Staking Staked resources anchor each miner's commitment to the network's stability. Staked, verified addresses allow for secure and direct communication across the network, reducing attack vectors and ensuring data consistency.Data Partitioning and Verification Before mining, each 16TB partition undergoes Matrix Packing. This structured process prepares data for efficient verification and aligns with Irys’s high standards for accuracy and accessibility."
    },
    {
      "path": "/learn/network-overview/bundling-transactions",
      "content": " Bundling optimizes blockchain uploads, combining multiple data transactions to reduce costs and support scalability for Web3.Bundling Transactions On Irys, uploading data is designed for scalability and efficiency through bundlers. Bundlers combine multiple transactions into a single package, called a bundle, and post it as one transaction to the network. Here’s how bundlers simplify and scale transactions: Within each bundle, individual transactions are referred to as DataItems. Each DataItem retains key properties found in regular data transactions—such as owner, data, tags, target, signature, and ID—allowing them to remain identifiable and functional within the bundle. Bundlers take on the reward costs for the entire bundle, meaning individual DataItems don’t need to include transaction fees. This structure keeps costs manageable while allowing developers to upload extensive datasets without incurring expensive fees on a per-transaction basis. By centralizing transaction fees at the bundle level, bundlers enable applications to cover their users' transaction costs if they choose. This opens up new possibilities for user-friendly, frictionless experiences. Bundling allows Irys to handle large data volumes without overwhelming the network, making it possible to build high-frequency or data-intensive applications at scale."
    },
    {
      "path": "/learn/network-overview/irys-gateway",
      "content": " The Irys Gateway provides fast, organized, queryable access to network data via GraphQL or REST APIs for developers.Irys Gateway The Irys Gateway is the interface that provides organized, reliable access to data on the network:Indexing The gateway continuously indexes all transaction metadata on Irys, ensuring that each item stored on the network is easily accessible. Bundles are indexed at a granular level to facilitate precise access and retrieval across multiple datasets.Querying Users can search data with customized queries using GraphQL or REST APIs. Irys also supports advanced search options by allowing users to assign custom metadata tags for each data upload.Serving Data Data retrieval is prioritized by the gateway to maintain efficiency: The gateway first checks its own local cache for recently accessed data. If data is not found locally, the gateway checks Irys’s broader optimistic cache for stored but less frequently accessed data. Finally, it accesses the miners’ network, reinforcing the availability and integrity of data across the system."
    },
    {
      "path": "/learn/protocol-overview/efficient-sampling-overview",
      "content": " Efficient Sampling ensures miners fulfill storage commitments, offering reliable, scalable, and cost-efficient data validation. ;Efficient Sampling OverviewOverview Efficient Sampling is Irys’s method for verifying that miners are fulfilling their storage commitments accurately and consistently. By systematically validating data across partitions, it ensures data reliability without placing unnecessary strain on miners or the network. At its core, Efficient Sampling allows miners to participate using affordable hardware while maintaining the rigorous standards required for blockchain storage. By verifying stored data in organized cycles, the network remains efficient and scalable, benefiting miners and developers alike.Why Efficient Sampling Matters Efficient Sampling tackles key challenges in blockchain storage verification, offering benefits that support miners, developers, and the network as a whole:Cost Efficiency Efficient Sampling reduces the hardware and computational costs of verifying large storage volumes. Miners can rely on standard HDDs rather than expensive specialized equipment, lowering both the barrier to entry and operational expenses.Scalability By organizing validation into logical, non-overlapping cycles, Efficient Sampling ensures that even as storage demands grow, verification remains consistent and manageable. For instance, a 16TB partition is methodically divided into 200MB ranges, sampled in a way that prevents redundant checks while maintaining complete coverage.Reliability Each range in a partition is systematically sampled, ensuring no data is overlooked or unverifiable. This systematic approach guarantees that stored data remains accessible and trustworthy, giving developers confidence in the integrity of their applications.Incentivized Mining Miners are rewarded for consistent uptime and verifiable storage, aligning incentives with network stability. By reducing costs and rewarding reliability, Efficient Sampling ensures mining remains profitable and encourages long-term participation.How Efficient Sampling Works Efficient Sampling verifies storage commitments using a structured process designed to balance performance, cost, and reliability. Its design enables verification of a 16TB partition within a 24-hour sampling window, which aligns with the time required to sequentially read the entire drive. This ensures that the system operates at the theoretical maximum efficiency for verifying storage.Step 1: Partition Ranges Each 16TB partition is divided into 200MB ranges to balance efficient verification with complete partition coverage.Step 2: List Creation Two lists are maintained for tracking progress: Unsampled Ranges: Tracks ranges awaiting verification. Sampled Ranges: Tracks ranges that have been validated within the current cycle.Step 3: Random Range Selection A range is randomly selected from the unsampled list. Randomization ensures unbiased verification and prevents miners from predicting or avoiding specific checks.Step 4: Verification Process The selected range is read and validated against cryptographic proofs created during Matrix Packaging. This ensures the range is intact and adheres to the miner’s storage commitments.Step 5: List Updates Once a range is verified, it is moved to the sampled list. This process avoids repeating checks within the same cycle and ensures all ranges are eventually covered.Step 6: Cycle Reset When all ranges in a partition have been sampled, the sampled and unsampled lists are swapped, and the process restarts. This guarantees ongoing, thorough verification across every partition. By operating within the theoretical limits of 16TB HDD performance, Efficient Sampling optimizes verification without unnecessary overhead, making it a foundational component of Irys’s storage infrastructure."
    },
    {
      "path": "/learn/protocol-overview/irys-consensus-overview",
      "content": " Irys integrates staking and useful Proof of Work to ensure decentralized mining, reliable storage, and data availability.Irys Consensus OverviewOverview Irys uses a consensus mechanism that combines useful Proof of Work (uPoW) with staking, aligning mining efforts with meaningful contributions to the network. Miners don’t just compete to produce blocks; they also commit to storing verifiable data, ensuring data availability and economic accountability. This system ties mining rewards directly to miners’ ability to maintain and prove access to historical data, while staking reinforces their commitments through financial penalties for noncompliance. The result is a secure, scalable, and efficient consensus model designed to support reliable onchain data storage.Why Staking MattersReliable Long-Term Data Miners pledge responsibility for 16TB partitions, ensuring historical data remains available and verifiable. Periodic validation checks incentivize ongoing compliance, linking mining rewards directly to reliable storage contributions.Economic Accountability Miners must lock $IRYS tokens as collateral, signaling their commitment to the network and creating clear economic consequences for failing to uphold their responsibilities. If a miner neglects their storage duties or acts maliciously, they forfeit their stake, protecting the network’s integrity. In practice, networks that incorporate staking observe far less adversarial behavior compared to systems relying solely on Proof of Work. This alignment of economic incentives reinforces Irys’s mission of building a trustworthy, reliable, and secure protocol for developers.Purpose-Driven Mining Mining on Irys isn’t just about expending energy to solve arbitrary computations. It’s about contributing to the protocol’s purpose. Useful Proof of Work transforms computational effort into a tool for verifying storage integrity, ensuring that: Miners actively prove they are maintaining their assigned partitions. Every computation aligns with the protocol’s goal of secure, accessible, and verifiable data storage. This approach shifts the focus from wasteful energy consumption to meaningful work, integrating mining with the protocol’s foundational mission. By tying block production directly to storage validation, Irys ensures efficiency without compromise.Supporting Network Growth The hybrid model integrates uPoW and staking to scale efficiently alongside network demands. Miners and developers benefit from stable block rewards, predictable costs, and a system that grows with increasing storage needs.How It Works Irys’s consensus mechanism operates through four distinct steps:Step 1: Staking and Pledging Miners stake $IRYS tokens as collateral, signaling their commitment to the network. They then pledge resources to specific 16TB partitions of data, which are mapped to their mining addresses. Partition AssignmentOnce a pledge is made, the protocol assigns a Partition ID, enabling the miner to prepare the partition through Matrix Packing and begin actively mining. Economic AccountabilityStaked tokens are forfeited if miners fail to meet their commitments, ensuring reliability. Unassigned pledges are returned, maintaining an organized storage onboarding process.Step 2: Data Storage Commitment Miners pledge storage to the network by assigning their resources to specific partitions. Each partition is actively mined, and rewards are distributed proportionally based on the miner’s contribution to the network’s total storage capacity. For example: A miner responsible for 10% of the network’s partitions can expect to earn approximately 10% of the block rewards. To safeguard decentralization, the protocol enforces a strict cap: no single miner can exceed 10% of the network’s hashpower, which is directly tied to the number of partitions they mine. This mechanism prevents any miner from accumulating disproportionate influence, ensuring the network remains balanced and resilient.Step 3: Useful Proof of Work Useful Proof of Work is the process of continuous sampling by miners, who generate cryptographic storage proofs tied to their assigned data. It functions through: Continuous Proof GenerationMiners actively validate their assigned partitions by generating storage proofs. These proofs serve as cryptographic evidence of their ongoing storage commitments. Block ProductionWhen a miner generates a valid storage proof that meets the network’s difficulty requirements, they can produce a block and broadcast it for validation. Other miners verify the proof, and upon acceptance, the miner earns block rewards. Economic AccountabilityMiners who fail to maintain storage face penalties, as the system detects failures within narrow proving windows. This discourages adversarial behavior and ensures reliable performance.Step 4: Reward Distribution Once a block is produced and validated, rewards are distributed to miners based on their storage contributions. This ensures the following: Proportional RewardsMiners responsible for larger shares of the network’s storage earn proportionally larger rewards. Incentive AlignmentReliable miners who consistently generate valid storage proofs receive steady rewards, reinforcing long-term engagement and network stability. This alignment between mining activity and reward distribution ensures that the network’s storage demands are met while keeping participation economically viable."
    },
    {
      "path": "/learn/protocol-overview/ledgers-overview",
      "content": " Irys’s multi-ledger architecture manages storage by segregating data for scalability, efficiency, and cost-effective onchain solutions. ;Ledgers OverviewWhat Ledgers Do Irys’s multi-ledger system divides data based on how long it’s needed and what it’s meant to do. Unlike the single-ledger approach of most blockchains, Irys takes a more efficient and flexible route.Submit Ledger The first stop for data on Irys. Here, data is held temporarily during a probation period. If the data doesn’t meet the upload criteria within the allotted time, it’s cleared—keeping the network efficient and ensuring that only high-quality data progresses. This process serves two key purposes: Preserving Ledger Integrity → Incomplete uploads are filtered out, preventing gaps in the permanent ledger and ensuring reliable data availability for applications. Detecting Miner Data Loss → By identifying miners who fail to maintain uploaded data, the protocol can replace them with new miners. This proactive replacement increases the durability of stored data and ensures that permanent data remains reliably accessible for validating programmable data contract execution. Data that successfully completes this stage moves on to the Publish Ledger for permanent, verifiable storage.Publish Ledger The Publish Ledger is where data that meets all standards is promoted for long-term, verifiable storage. While data resides in the Submit Ledger, miners storing that data circulate proofs of ingress—cryptographic certifications verifying that the data has been successfully uploaded and replicated across the network. Once enough ingress-proofs are collected, the transaction is eligible for promotion to the permanent ledger. This process not only verifies that the data has been uploaded correctly but also ensures multiple copies exist across the network. These assurances form the foundation of data availability in the permanent ledger and provide the consensus guarantees essential for enabling programmable data.Why Ledgers Matter Irys’s use of multiple ledgers is a deliberate solution to persistent blockchain storage challenges:Scalability Irys’s multi-ledger system addresses scalability by dividing data into purpose-specific ledgers, preventing congestion and bottlenecks. This design ensures that storage and execution activities remain independent, so smart contracts and storage transactions don’t directly compete for space. However, scalability isn’t just about slicing data into separate ledgers. True scalability comes from Irys’s ability to manage its network resources proactively. Combined with Matrix Packing, Irys’s use of capacity partitions allows the protocol to onboard storage resources ahead of demand. This means that as ledgers grow, the network doesn’t have to wait for new miners to join or add resources—those resources are already available. This dynamic capacity ensures that Irys can ingress large amounts of data rapidly, providing developers with a consistent and efficient experience, even as demand increases. Cost Efficiency Users only pay for the storage they need. The Submit Ledger serves a specific role in the protocol as a temporary holding area for new data, while the Publish Ledger provides secure, permanent storage for data requiring long-term reliability. As the network evolves, additional term ledgers with defined durations will be introduced, offering developers even more options to optimize costs by tailoring storage to their exact needs. Unlike other systems where costs fluctuate unpredictably, Irys anchors its pricing to the physical cost of storing data, not the volatile ups and downs of token markets. This pricing model provides developers with affordable, predictable access to onchain storage without compromising performance or scalability.Data Integrity Every piece of data in Irys’s ledgers is made tamper-proof through the use of cryptography—Merkle trees, whose roots are included with each storage transaction. This ensures that data cannot be altered without detection and remains accessible across the network. To address the most common cause of data loss—hardware failures—Irys maintains multiple replicas of data distributed globally. This redundancy ensures that data remains intact and available, even in the face of localized disruption. Miners are held accountable for preserving data through economic commitments, backed by staked tokens and penalties for noncompliance. This combination of cryptographic proofs, global replication, and miner accountability ensures that data on Irys is consistently verifiable and reliable for developers who depend on it. Adaptability Irys’s ledger system is designed to expand with the needs of developers. As new storage requirements arise, additional ledgers can be created, avoiding rigid, one-size-fits-all models and enabling storage solutions tailored to specific demands. This means that the longer the network exists, the more valuable it becomes. How Ledgers Work Irys’s ledger system is designed to manage data efficiently from submission to permanent storage, ensuring reliability, verifiability, and scalability at every step.Replication Across Partitions Data in the Publish Ledger is replicated across multiple partitions, ensuring resilience against data loss and maintaining availability during programmable data execution. This replication model applies not only to the permanent ledger but also to the active portion of the Submit Ledger. By distributing data globally across partitions, Irys ensures: Fault tolerance, even in the face of localized disruptions. Rapid retrieval and availability for developers working with programmable data.Entry to the Submit Ledger All data begins in the Submit Ledger, which acts as the network’s entry point. Here, the protocol provides the storage needed to receive uploads and generate ingress-proofs—cryptographic evidence that verifies data has been successfully uploaded to the network. To advance from the Submit Ledger, data must: Have sufficient ingress-proofs circulated by the miners storing it. Be backed by funds to pay for storage costs.Promotion to the Publish Ledger Once data has enough ingress-proofs and meets all requirements, it is promoted to the Publish Ledger. This step ensures: Data becomes part of the permanent ledger. Verifiability and availability are guaranteed through the network’s cryptographic and economic commitments. The active portion of the Submit Ledger is also replicated across multiple partitions, providing redundancy and safeguarding against potential disruptions.Continuous Integrity Checks Miners are central to ensuring the reliability and verifiability of data stored on Irys. They achieve this through mechanisms integrated directly into the mining process:Constant Proof GenerationAs part of mining, every miner generates storage proofs to demonstrate they are actively maintaining their assigned data. These proofs are evaluated by the network, and only those meeting the network’s difficulty threshold allow miners to produce a block and earn rewards. Challenge-Response SystemIf a miner’s integrity is called into question, the protocol allows any participant to issue a storage challenge. The miner must respond within a limited window by producing a valid proof that confirms they are actively storing the required data.The system is designed to prevent miners from retrieving data from elsewhere or repacking it on demand, as this would take too long and miss the proving window—resulting in the miner’s economic commitments being slashed. This system creates a strong disincentive for adversarial behavior, ensuring that miners maintain their storage commitments consistently. It establishes a reliable, self-regulating framework that underpins the reliability of Irys’s network.Scalability Through Modular Expansion As data demands grow, Irys can create new ledgers tailored to specific needs. This modularity enables the network to scale efficiently without compromising performance or reliability. Combined with the dynamic management of capacity partitions, this approach ensures that the network is always prepared to handle increasing data volumes, maintaining smooth operations and a reliable developer experience."
    },
    {
      "path": "/learn/protocol-overview/matrix-packaging-overview",
      "content": " Matrix Packaging optimizes decentralized storage by ensuring miner accountability, data integrity, and cost-efficient verification. ;Matrix Packaging Overview Packing adds cryptographic fingerprints to stored data, proving miners provide unique resources. This prevents adversarial claims of false storage capacity. Irys introduces Matrix Packing, a novel approach to data verification. This method ensures miners provide unique storage resources while deterring adversarial behavior.Overview Matrix Packaging is Irys’s solution to a fundamental challenge in blockchain storage: ensuring data is verifiable, scalable, and cost-effective while maintaining efficiency and performance. Unlike traditional storage systems that rely on computationally expensive and time-consuming verification methods, Matrix Packaging focuses on verifying miner behavior by embedding cryptographic properties into each partition. This system ensures that: Every miner stores unique, intact copies of data, creating a verifiable and accountable storage framework. Verification is fast and efficient, even as storage needs grow. Miners are economically incentivized to maintain accurate data replicas, supporting network reliability. Beyond its role in storage, Matrix Packaging also indirectly supports programmable data by guaranteeing data availability and replication integrity, ensuring that applications relying on Irys can function responsively and at scale.Why Matrix Packaging Matters Efficient, reliable storage is the backbone of any blockchain network, but achieving it at scale is no small task. Without a deliberately optimized system, miners would face excessive computational burdens, developers would deal with high fees, and the accuracy and reliability of stored data would be at constant risk. Matrix Packaging addresses these challenges with measurable and economic guarantees:Parallel Efficiency Matrix Packing can process data simultaneously across multiple threads, significantly reducing time and energy costs. This parallelization makes storage preparation on Irys faster and more economical than other systems reliant on sequential or heavy computation.Verifiable Storage Every chunk of data is tied to a miner through a cryptographic sequence of hashes. Sequential hashing creates a dependency structure where even a minor alteration invalidates the entire segment, making tampering immediately detectable. This guarantees that the data developers rely on remains trustworthy while ensuring miners are held accountable for maintaining storage integrity.Predictable Costs Matrix Packaging’s true strength lies in its parallel processing capabilities, offering a cost-effective and energy-efficient approach to storage preparation and verification. Unlike systems such as Arweave’s RandomX or Filecoin’s zk-sealing, which rely on computationally expensive and tediously slow sequential processes, Matrix Packaging takes a predictable amount of time per chunk while enabling parallel operations. This drastically reduces both the time and energy costs associated with packing. Key advantages include: Lower Computational OverheadBy avoiding resource-intensive methods, Matrix Packaging minimizes computational demands, streamlining storage preparation and reducing costs. Scalable ParallelismMiners can process multiple chunks simultaneously, supporting large-scale storage operations without bottlenecks. Energy EfficiencyParallel processing significantly reduces energy consumption, reinforcing Irys’s commitment to sustainability and cost-effectiveness. This approach ensures that storage verification on Irys remains efficient, cost-effective, and scalable, even as network demands grow.Economic Incentives for Miners Miners are rewarded for maintaining storage in a state ready for verification, aligning their incentives with the network’s need for continuous data availability. This guarantees that storage commitments are upheld and that miners are always prepared to meet the demands of the network.Optimized Data Ingress Matrix Packaging allows new data to be integrated into existing storage without repacking the entire structure. Instead, data is XOR’d into place, drastically reducing latency and computational overhead. This means a developer can upload new datasets rapidly, even during peak network activity, while miners avoid the high costs of full reprocessing.How Matrix Packaging Works Matrix Packaging transforms data storage—which is naturally very messy—into an organized, verifiable process that balances efficiency, reliability, and scalability. Here’s how it works:Step 1: Data Partitioning Irys’s storage begins with 16TB partitions, a practical size chosen to align with the capacity of modern hard drives. These partitions form the raw storage resource that miners pledge to the network. Before these partitions can store data, they are divided into manageable chunks and processed through Matrix Packing. This process cryptographically prepares the chunks for secure storage, making them ready to receive data reliably and efficiently. By structuring storage into 16TB units, Irys balances high storage density with hardware compatibility, enabling miners to scale their resources effectively.Step 2: Chunk Division Each partition is broken into smaller 256KiB chunks, creating manageable units for miners to interact with during storage and verification. This structure supports parallel processing, reducing delays in verification.Step 3: Segment Creation Each chunk is further divided into 32-byte segments that include unique entropy generated from SHA-256 hashing, making each segment cryptographically distinct. These cryptographic distinctions prevent duplication and ensure that each miner maintains a unique data replica.Step 4: Sequential Hashing Segments are hashed in sequence, with each hash depending on the output of the previous segment. This process creates a tamper-proof dependency chain across the chunk, ensuring that even a single altered byte invalidates the entire sequence. In addition to ensuring data integrity, sequential hashing enforces a consistent, fixed processing time for packing each chunk.Step 5: Multi-Layer Hashing Each chunk undergoes repeated hashing across multiple layers, with the protocol setting parameters to ensure a consistent and predictable packing or unpacking time of approximately 3.5 seconds per chunk. While Irys’s per-chunk processing time is longer than Arweave’s RandomX (40 milliseconds per chunk), the system's design enables significant efficiency gains when processing multiple chunks. RandomX is computationally intensive, unpacking chunks sequentially and utilizing all system cores and memory. In contrast, Irys leverages GPU parallelization to unpack thousands of chunks simultaneously, completing the entire process in just 3.5 seconds. This efficiency becomes increasingly advantageous as the number of chunks grows, making Irys ideal for high-throughput data storage and retrieval.Impact on Block Times The Matrix Packaging process establishes a minimum block validation time of 3 seconds. This ensures that miners have enough time to validate and prepare data without disrupting Irys’s typical Proof of Work block times of 9–12 seconds. As a result, the network remains stable and efficient, even during periods of high demand."
    },
    {
      "path": "/learn/protocol-overview/partitions-overview",
      "content": " Partitions in Irys organize, replicate, and validate storage, supporting scalability and miner accountability in decentralized systems.Partitions OverviewWhat Partitions Are In the Irys network, partitions are the fundamental building blocks of the protocol, serving as the core units of data organization and verifiability. Each 16TB partition operates as the essential structure within Irys’s multi-ledger framework, enabling miners to prove their storage commitments to the network. Partitions play a dual role: Managing Storage: They handle both empty capacity and the distribution and replication of ledger data across the network. Ensuring Verifiability: Partitions are the foundation of verifiability on Irys, tying miner commitments directly to specific data. This allows users to reference partitions to confirm replication and the reliable storage of their data. Additionally, by assigning specific miners to specific partitions, Irys ensures: Direct Accountability: Miners are economically tied to the partitions they manage, incentivizing reliable performance. Efficient Access: Miners can locate and retrieve specific data for programmable data execution, ensuring seamless availability when needed. By anchoring storage, verifiability, and data access, partitions are not just practical but pivotal to the reliability and scalability of the Irys network.Why Partitions Matter Partitions are the practical foundation of Irys’s multi-ledger storage layer. They make working with data efficient, fault-tolerant, verifiable, and affordable at a fixed cost—key attributes any developer needs to trust a network.Smart Scaling Irys uses partitions to manage the storage and replication of its data ledgers, while also onboarding miners to provide empty storage capacity ahead of when it’s needed. This capacity is managed dynamically, ensuring: There’s always enough storage capacity available to meet the demands of the network. Excess capacity doesn’t accumulate, keeping the protocol’s costs sustainable by ensuring miners are fairly compensated for their participation. This system makes scaling seamless and cost-effective, so developers aren’t caught off guard by surprise costs or limitations as their storage needs grow.Reliable Redundancy Partitions on Irys are evenly distributed across the network, ensuring that replicas of data are replicated globally. This redundancy provides: Fault-Tolerant: Resistant to failures caused by natural disasters (e.g., hurricanes, earthquakes) or other localized disruptions. Globally Accessible: Consistent availability of ledger data across the network, enabling rapid retrieval and supporting programmable data execution. By replicating data evenly across the network, Irys enhances resilience and optimizes access, ensuring that users and miners can interact with data efficiently, regardless of their location.Cost Stability Each step of a partition’s lifecycle—pledging, packing, mining, and orderly exit—has a purpose. Miners commit resources and are rewarded based on their reliability and performance. This structure keeps costs predictable for users and discourages behavior that could disrupt the network. You know what you’re getting, and you know what you’re paying.Flexible Storage for Real Needs Irys supports both capacity partitions (standby storage) and data partitions (actively storing ledger data), enabling storage solutions tailored to different needs—whether short-term or permanent. By building data ledgers out of partitions, the protocol gains well-defined ranges of data that: Can Be Dynamically Incentivized: Miners can be incentivized to store specific partitions or, when no longer needed, stop receiving rewards for them. Enable Permanent and Term Storage: This flexibility allows Irys to support both permanent and term-based data storage within a single protocol, adapting to the specific demands of developers and applications. This partition-based approach ensures resources are used efficiently, aligning with the unique requirements of applications without unnecessary overhead.How Partitions WorkTypes of Data Partitions Irys uses two main types of partitions: Capacity Partitions: Standby storage that’s held in reserve, ready to be activated as needed. Data Partitions: Actively used within a ledger for data storage and verification. Each data ledger slot assigns up to 10 partitions for data replication. This replication ensures that data is not only stored but stored reliably across a globally distributed network of nodes. By having standby capacity and multiple data partitions, Irys can scale with demand, maintain continuous data availability, and support programmable data smart contract interactions in a responsive and reliable manner.Replication Each data ledger slot has multiple partitions, meaning the same data exists in multiple places. If something happens to one partition, the data remains available elsewhere in the network. Replication makes data fault-tolerant and durable, providing a safety net against data loss and maintaining uptime for all users. Additionally, it distributes data globally, enabling rapid retrieval by nodes during programmable data execution. This ensures seamless interaction and availability for smart contract operations.Partition Lifecycle Each partition within the Irys network follows a defined lifecycle, establishing order and predictability in how data is managed, accessed, and stored.Initial Set Up And Pledging Miners start by setting up at least one partition’s worth of storage on their mining machine, preparing it to meet the protocol's standards. Once the storage is ready, miners pledge it to Irys and wait to be assigned a Partition ID. The Partition ID assignment enables miners to proceed with packing their partitions, marking the next step in their commitment to the network. Unassigned pledges are returned, ensuring an organized and efficient system for onboarding storage resources. This initial commitment establishes a base level of accountability, setting the stage for the rest of the lifecycle.Packing through Matrix Packaging Once assigned, miners prepare their partitions through Matrix Packing. This process embeds a unique miner identifier into each partition, ensuring that each replica on the network is distinct and verifiable. The most important function of Matrix Packing is proving—and incentivizing—that miners are storing unique replicas of partitions on disk. By optimizing partitions for quick verification, Matrix Packing establishes the foundation for secure storage that is upheld throughout mining and block production.Mining and Block Production Once partitions are packed, miners continuously generate storage proofs—cryptographic attestations that demonstrate they are actively maintaining their assigned data. These proofs aren’t about verifying the data itself but rather proving to the network that miners are upholding their storage commitments. By successfully submitting a valid storage proof, miners earn the right to produce a block and claim the associated rewards. This system ties mining rewards directly to sustained, verifiable storage, aligning miner incentives with the network’s reliability and stability.Ledger Assignment As data storage demands grow, Irys dynamically assigns capacity partitions to active data roles within its ledgers. This process prioritizes miners who have consistently demonstrated reliable participation, ensuring that sustained contributions are rewarded and network reliability is reinforced. These incentives are carefully designed to minimize adversarial behavior, streamlining network performance and ensuring the responsiveness required for programmable data interactions.Orderly and Disorderly Departures Miners can exit in one of two ways: Orderly Departure: The miner submits a formal departure request, allowing Irys to reassign storage without disruption. After a timeout period, the miner’s pledge is refunded, ensuring a smooth transition that maintains the network’s balance and reliability. Disorderly Departure: In cases of adversarial behavior, such as neglecting storage commitments or malicious actions, the miner forfeits their stake. The protocol quickly reallocates storage to maintain data availability and continuity. Both methods are actively managed by the protocol to safeguard data integrity and ensure global distribution—a key component to enabling fast, responsive programmable data."
    },
    {
      "path": "/learn/protocol-overview/programmable-data",
      "content": " Programmable data embeds logic into onchain assets, enabling automated, reliable execution for decentralized smart contracts.Programmable DataRange Specification To interact with Irys’s ledger data during smart contract execution, each transaction specifies the range of data chunks it requires (A chunk range specifier). These ranges are designed to align with Ethereum’s EIP-2930 access lists, ensuring compatibility and efficient interoperability with existing developer tooling. The format for specifying ranges is: :: partition_index: (26 bytes) The index of the partition in the Publish Ledger containing the first chunk. offset: (4 bytes) The starting chunk offset within the partition. chunk_count: (2 bytes) The number of sequential chunks to retrieve starting from the offset. This structure allows precise targeting of data stored within Irys’s partitions, enabling efficient data retrieval for execution. In addition, Programmable Data also offers Byte Read Ranges, which build on top of chunk read ranges to provide easy access to specific parts of a transaction's data. the format for a byte read range is: ::: partition_index: (26 bytes) The index of the partition in the Publish Ledger containing the first chunk. offset: (4 bytes) The starting chunk offset within the partition. chunk_count: (2 bytes) The number of sequential chunks to retrieve starting from the offset.Pricing for Programmable DataBase Fee Unpacking and deserializing data for IrysVM incurs computational overhead, which is mitigated through a base fee to prevent spam. During the testnet phase: The base fee for 1MB of Programmable Data is $0.01. Programmable Data transactions have a minimum cost of $0.01. This pricing ensures affordability while maintaining system integrity.Congestion pricing / Priority Fees Dynamic pricing adjusts access costs to Irys’s data ledgers based on market demand and network congestion, inspired by Ethereum’s fee adjustment model. With testnet block times of 30 seconds, the network can process up to 7,500 chunks per block (at 250 chunks/second). Each chunk represents 256KiB of data. Increase:If more than 50% of block capacity is used, the base fee scales linearly up to +12.5% when all 7,500 chunks are consumed. Decrease:If no chunks are used, the base fee decreases by up to -12.5% per block, with a minimum floor of $0.01 and no upper limit. This congestion pricing model avoids unpredictable spikes in costs, providing developers with consistent economic efficiency, even during peak demand.Data Availability & Synchronization Irys ensures robust data availability through an efficient synchronization mechanism that leverages both peer-to-peer sharing and miner-based retrieval. This multi-layered approach guarantees data accessibility under all conditions.Peer-to-Peer Broadcasting Nodes broadcast Programmable Data (PD) transactions to their peers, marking whether they already possess the requested chunks. Peers that lack chunks can request them directly from broadcasting nodes.Request and Response Broadcasting nodes track which peers need the chunks and send them upon availability. Receiving peers rebroadcast transactions, tracking peers that lack chunks to maintain propagation.Fallback to Miners If a peer fails to receive chunks within a predefined propagation delay (200ms for testnet), it queries miners responsible for the relevant partitions. The ledger identifies replicas, and the node randomly selects a partition for retrieval. This fallback ensures reliable access, even under heavy network demand.Verifying Data for Execution Transaction validation for Programmable Data involves verifying the integrity and availability of the requested chunks. Nodes can retrieve and validate chunks through several pathways:Cached Unpacked Chunks Nodes leverage previously cached, verified chunks validated against their Merkle roots, ensuring readiness for IrysVM execution.Local Packed Chunks If the node mines the partition containing the requested chunks but only has packed versions, it performs the following steps: Generates the entropy for the specified chunk range. Unpacks the chunks using the computed entropy. Builds a Merkle root from the unpacked chunks. Looks up the transaction that posted the chunks using the block index. Compares the computed Merkle root with the one stored in the transaction. If valid, shares unpacked chunks with peers lacking them.Received Unpacked Chunks When receiving unpacked chunks from peers, the node validates the data by: Following steps 4–5 from the \"Local Packed Chunks\" process.Requesting Chunks from Miners If the node cannot retrieve chunks through caching or peers within the expected propagation delay (D = 200ms for testnet): The node queries the ledger to identify partitions responsible for storing the chunks. It selects a partition replica at random and requests the chunks. If the chunks are provided in a packed state, the node unpacks them and validates using steps 4–6 from the \"Local Packed Chunks\" process. This comprehensive validation ensures the accuracy and reliability of programmable data before execution, maintaining the integrity of smart contract interactions."
    },
    {
      "path": "/learn/protocol-overview/transactions-overview",
      "content": " Irys uses multi-blocklanes to handle data, token, and compute transactions separately, ensuring scalability and cost predictability.Transactions OverviewOverview Transactions on Irys are declarations of intent—tools users and developers rely on to interact with the network. Regardless of the type, every transaction is handled through a system designed to keep costs low and performance high. At the core of this system is a key innovation: multiple blocklanes. Unlike traditional blockchains, where all transaction types compete for space and resources, Irys divides operations into specialized lanes. Each blocklane on Irys is optimized for its specific purpose—whether it’s processing a token transfer, storing data, or running a smart contract. This means that each transaction type runs exactly where it needs to, without competing with unrelated operations. By dedicating resources to specific tasks, Irys ensures that: Token transfers remain fast, even during heavy network usage. Data uploads are affordable, no matter how much information is being stored. Smart contracts execute reliably, with predictable performance and costs.Why Transactions Matters The way a blockchain handles transactions determines how efficient, reliable, and scalable it can truly be. On many platforms, a single blocklane is forced to process everything—value transfers, storage, computation—leading to bottlenecks, rising fees, and inconsistent performance. Irys solves this by dividing transactions into multiple blocklanes, each optimized for a specific purpose.Efficiency On traditional chains, storage and computation transactions compete for space, leading to delays and inflated fees. Irys’s separate blocklanes eliminate this conflict, so storage transactions don’t slow down token transfers, and computation tasks don’t drive up storage costs.Predictable Costs Irys ensures that each transaction type is priced according to its actual resource use. Storage fees are calculated upfront with stable pricing models, while compute fees adjust dynamically based on demand. This means you always know exactly what you’re paying for.Scalability As demand grows, Irys’s multi-blocklane architecture allows each type of transaction to scale independently. This means that an influx of data uploads doesn’t slow down token transfers or execution tasks. Irys adapts to growth without compromising performance. Types of TransactionsValue Transfers What It Does: Enables the movement of tokens between accounts. How It Works: Value transfers are processed in a dedicated blocklane optimized for speed and efficiency. This blocklane is purpose-built to handle token movement without being slowed by storage or computation operations.Data Transactions What It Does: Writes data directly to Irys’s storage layer. How It Works: Data transactions allow users to upload information to Irys’s multi-ledger architecture. The process begins in the Submit Ledger, where data is temporarily held for validation. Each chunk of data associated with a transaction must be uploaded, and ingress proofs generated, ensuring that the data is securely logged and verifiable. Think of it as a checkpoint where data establishes its place on the network before advancing.Once verified, the data is promoted to the Publish Ledger, where it becomes permanent and backed by cryptographic proofs (Merkle roots). Users pay a one-time upfront fee based on the storage duration and size, ensuring cost predictability. After promotion, data is replicated across the network, becoming part of a globally accessible, resilient system ready for integration into programmable data applications.Matrix Packing optimizes this process by structuring data for efficient verification and accessibility, reducing the computational burden on miners and ensuring scalability even as network demands grow. Compute Transactions What It Does: Running smart contracts operations through Irys’s execution layer—the IrysVM. How It Works: Compute transactions are processed through IrysVM, the execution layer built to handle onchain logic and smart contracts. These transactions interact directly with data stored in the Publish Ledger, eliminating the need for external systems. Fees are based on the computational demand of the transaction, and a dynamic adjustment mechanism ensures that the network remains efficient during high usage periods. When demand exceeds a certain threshold, fees increase incrementally, prioritizing important transactions without disrupting the network or inflating costs.Stake Transactions What It Does: Activates a miner’s address for network participation. How It Works: By locking a specific amount of $IRYS tokens, miners activate their addresses and gain access to mining operations. This stake is effectively collateral. If miners don’t play by the rules or fail to maintain performance, they stand to lose it. This alignment of incentives keeps the network secure and dependable.Pledge Transactions What It Does: Locks in a miner’s responsibility for specific storage partitions. How It Works: Every pledge transaction links a miner to a specific 16TB partition. During Matrix Packing, the miner’s unique identifier is embedded directly into the partition, creating a permanent record of who’s responsible for the data. Miners put up collateral to cover their storage commitments, and if they fail—by losing data or neglecting their role—they forfeit their pledge. This ensures data availability and makes accountability more than just a promise—it’s built into the system."
    },
    {
      "path": "/learn/what/how-irys-solves-these-problems",
      "content": " Irys combines multi-ledger architecture, stable pricing, and miner incentives to create a scalable, decentralized ecosystem powered by programmable data.How Irys Solves These ProblemsAddressing the Bottleneck of Complexity Every inefficiency costs time and money. Today, developers wrestle with disjointed systems, piecing together fragmented storage solutions just to get their applications running. This complexity is a drain on resources, slowing progress and driving up costs. Irys offers a clear, straightforward answer: a unified network that is optimized for both storage (data) and execution (smart contracts)—meaning that for the first time, smart contracts can natively access the data stored within the same network. This integration eliminates the needless back-and-forth between protocols, allowing developers to streamline their workflow, reduce expenses, and focus entirely on innovation.Addressing the Stagnation of Static Data At its core, Irys integrates a multi-ledger architecture that optimizes how data transitions from temporary validation to permanent storage. This system is designed to balance efficiency, reliability, and cost-effectiveness, while laying the groundwork for advanced applications that need programmable data. All data on Irys will first enter through the Submit Ledger, a space where it’s temporarily held for validation. Once verified, it earns its place in the Publish Ledger, where it becomes permanent and, most importantly, trustworthy. Think of it as promoting data through a life cycle, from temporary use to verified permanence, where it becomes part of a larger, interconnected system. While Irys will launch with two ledgers to start, its protocol is built for adaptability. Developers and users can expect the creation of additional term ledgers tailored to specific needs, whether for short-term or permanent storage. This dynamic approach ensures that as utilization grows, Irys evolves in response to real demand—not assumptions. In this way, Irys isn’t just prepared for the future—it’s shaped by the needs of the people building it.Addressing the Threat of Centralization Centralization undermines the foundation of blockchain’s promise—distributed power, trustless systems, and resilience against single points of failure. When control is concentrated among a few, the system becomes vulnerable to manipulation. This is a fundamental flaw that first-generation datachains haven’t effectively addressed. Irys takes proactive measures to prevent centralization through its unique consensus mechanism, blending Proof of Work (PoW) with Proof of Stake (PoS). Here’s how: Stake-Activated Mining: Miners must stake resources to activate a mining address on the network, signaling their commitment. Controlled Hashpower Distribution: The protocol enforces that no mining address can control more than 10% of the network’s mining hashpower. This ensures power remains distributed and controls the risk of a single entity dominating the network. Graduated Commitments: Adding a new partition to an existing mining address is significantly more cost-effective than creating a new address. This design makes it uneconomical for miners to operate multiple mining addresses, removing any financial incentive to do so.Addressing the Burden of Unpredictable Costs In the world of business, uncertainty is a killer. You can’t budget, you can’t plan, and you certainly can’t innovate when costs fluctuate wildly. Most blockchains today leave developers guessing, with storage costs swinging unpredictably and threatening to derail projects before they even get off the ground—Irys puts an end to that. We’ve built a system where pricing isn’t a mystery but a promise. Every block on Irys carries a timestamp and a miner’s best approximation of the USD/IRYS price. These price estimates are tracked over time, and through an Exponential Moving Average (EMA), we stabilize the cost of storage. This means predictable, reliable pricing. But we didn’t stop there. Miners are incentivized to keep their price estimates accurate. If they report something off, their blocks can be rejected by other miners. It’s a self-correcting system that keeps everyone honest and keeps your costs stable. Builders don’t have to gamble on storage anymore. With Irys, you know exactly what you’re getting and exactly what it’s going to cost."
    },
    {
      "path": "/learn/what/what-a-datachain-is",
      "content": " A blockchain optimized for decentralized, cost-efficient onchain data storage, offering scalability and verifiability for Web3 applications.What a Datachain Is A datachain is a blockchain designed for one task: storing data. Unlike blockchains optimized only for executing smart contracts—where storage is exceptionally expensive—datachains focus on keeping data onchain affordably. They make it possible to store large quantities of data without the excessive costs associated with typical execution-heavy blockchains like Ethereum or Solana. The early datachains solved one clear problem: the need for economical onchain storage. But while they excelled at storing information, they stopped there. A stored piece of data remains just that—stored. It isn’t part of any system where it can react, interact, or fuel other applications. The next step is making stored data useful and versatile, capable of driving an ecosystem."
    },
    {
      "path": "/learn/what/what-irys-is",
      "content": " The first programmable datachain, Irys transforms onchain data into an active, verifiable asset for decentralized ecosystems.What Irys Is Imagine, for a moment, the dawn of the internet. In those early days, it was little more than a scattered network of static web pages—useful, yet fundamentally constrained. The true transformation occurred when the internet became programmable; that shift unlocked email, social media, gaming, search engines (and more)—enabling a vast ecosystem where data, applications, and people could connect in ways previously unimaginable. Now, something similar is happening onchain. Until recently, datachains operated only as repositories, like lonely vaults where data was held—static, isolated, untouchable. But what if data weren’t just stored, but dynamically engaged across systems, flowing, adapting and evolving to power applications beyond just storage? Irys is that vision realized—something beyond a datachain, beyond data storage. It's something entirely new: the world's first programmable datachain, where data doesn't just exist; it becomes active, fluid, valuable across applications. And it's this evolution—from passive to programmable—that marks the true primitive."
    },
    {
      "path": "/learn/what/what-irys-isnt",
      "content": " Not limited to storage or computation, Irys integrates decentralized storage and programmable data capabilities for broader applications.What Irys Isn't To understand what Irys does, let’s first clarify what it’s not. Most blockchains you know—Ethereum, Bitcoin, Solana—are built for deploying smart contracts, processing payments, and executing code. But when it comes to storage, they’re inadequate: storage is limited, hard to access, and can be astronomically expensive. These networks simply weren’t designed for data storage. To address this issue, the first datachains were created, designed specifically to store large volumes of data affordably onchain. They did their job well enough—storing data relatively cheap, holding it somewhat securely, but similar to how blockchains optimized for execution came with data limitations, datachains optimized for only storage came with their own limitations: data was locked in place, unable to interact or support broader applications. It’s like a library where the books are stored in locked rooms, out of reach."
    },
    {
      "path": "/learn/what/what-is-irys-headers",
      "content": " Irys is the first L1 programmable datachain, optimizing data storage and execution, enabling new onchain web services and dynamic applications.What is Irys?{[{\"title\": \"What is a Datachain?\",\"illustration\": \"/illustrations/sized-down/rocket.png\",\"href\": \"/learn/learn-about-irys/what-is-datachain\"},{\"title\": \"Programmable Data\",\"illustration\": \"/illustrations/sized-down/pencil.png\",\"href\": \"/learn/why-build-on-irys/programmable-data\"},{\"title\": \"Protocol Overview\",\"illustration\": \"/illustrations/sized-down/detective.png\",\"href\": \"/learn/protocol/protocol-overview\"},{\"title\": \"Build on Irys\",\"illustration\": \"/illustrations/sized-down/portal.png\",\"href\": \"/build/welcome-builders\"}].map(({ title, illustration, href }) => ({title})) }Irys is the first L1 programmable datachain, designed to optimize data storage and execution. By combining storage and execution, it significantly increases the usefulness of blockspace, enabling a wider range of web services to come onchain that aren’t possible right now.Irys empowers developers to create and innovate like never before. With Irys, builders can eliminate dependencies, integrate efficient onchain data, and unlock new possibilities for dynamic, real-time applications—all within a unified platform."
    },
    {
      "path": "/learn/what/why-irys-exists",
      "content": " Irys addresses inefficiencies, centralization, and cost unpredictability in datachains, enabling scalable, programmable data.Why Irys ExistsThe Complexity Problem Developers face a labyrinth of fragmented storage solutions. Each system adds layers of complexity, leading to higher costs, slower processes, and bottlenecks that stifle innovation. Managing these disparate systems is far more than a simple inconvenience—it’s a major barrier to scaling applications effectively. The Static Data Problem Data without support for meaningful interaction is data that’s stuck. Early datachains treated storage and execution as separate worlds. This static nature of stored data limits its potential, making it difficult to build applications that make commitments about that data. It’s a system built for storage, not for innovation. The Centralization Problem True decentralization means no single entity holds too much power. Yet, first-generation datachains are dominated by a few players, risking manipulation and reducing the trust and security the system promises. This centralization undermines the very principles blockchains were designed to uphold. The Unreliable Pricing Problem Unpredictable, high costs are a developer’s nightmare. Building applications that rely on onchain data should be an economically feasible venture, but fluctuating storage fees make it difficult to budget and plan long-term projects. Without cost stability, innovation is stifled, and many promising ideas never leave the drawing board."
    },
    {
      "path": "/learn/why/why-irysvm",
      "content": " IrysVM bridges onchain storage and computation, enabling affordable, integrated smart contract execution directly within the ledger. ;Why IrysVMWhat is IrysVM? IrysVM is the virtual machine at the heart of Irys, built to make smart contracts and data work together efficiently and directly. While most blockchains treat data storage and smart contract execution as two separate functions, IrysVM integrates them under a single network. This lets smart contracts interact directly with data in ways that simply aren’t possible on other platforms. IrysVM offers the same benefits as an Ethereum Virtual Machine, but with a unique advantage: it’s built for direct access to Irys’s data ledgersWhy IrysVM Matters The main advantage of IrysVM is that it allows developers to attach specific properties to data and have them be programmable, making it useful across applications without requiring that programability and data storage reside in separate protocols. In practical terms, this means data on Irys can carry out tasks like enforcing ownership rights, automating royalties, managing access permissions, verifying uploaded data, and effectively executing any pre-defined instructions within the smart contract. For developers, it opens up a straightforward path to building applications where data is more than just stored information—it’s functional, adaptable, and cheap to work with. Additionally, with IrysVM’s design, storage and smart contract transactions are kept on separate processing lanes. This prevents the typical competition for blockspace that can drive up costs on other blockchains. Developers gain predictable transaction costs and stability, even as storage needs increase, making it simpler to scale applications over time."
    },
    {
      "path": "/learn/why/why-programmable-data",
      "content": " Programmable data integrates smart logic into stored data, enabling advanced execution across decentralized blockchain applications. ;Why Programmable DataWhy In most datachains today, data is a static, passive entity. It’s collected, stored, and left to rest. Sure, these datachains are a significant improvement over storage on execution chains, but the data itself is stagnant. It doesn’t move, adapt, or do anything on its own. But what if data could actually work for you? What if it could act, respond, and evolve through smart contracts that execute pre-defined logic? That's what programmable data does. Putting Data to Work On Irys, data is equipped with instructions, carrying specific properties and rules as it moves across applications. This means that data can actively execute ownership rights, enforce royalty structures, uphold encryption standards, or even carry interaction rules with other applications. Each piece of data on Irys has the potential to carry these embedded properties—and much, much more. This isn’t just data sitting around. It’s data with a job to do, carrying its purpose within it and executing that purpose as it interacts with smart contracts and applications across an ecosystem.The Role of IrysVM What makes this kind of programmable data possible on Irys? It’s the native pathway between the data layer and IrysVM, allowing instructions to be executed directly onchain at a fraction of the typical cost. Unlike traditional execution chains where fragmentation and offchain solutions drive up costs, Irys provides a fully integrated, affordable approach. Everything happens onchain, reducing the headaches of working with data on first-generation datachains, while also opening new possibilities for applications and use cases that would otherwise be prohibitively expensive to build."
    },
    {
      "path": "/learn/why/why-verifiability",
      "content": " Verifiability guarantees data reliability, using cryptographic proofs to ensure trust, accessibility, and integrity onchain. ;Why VerifiabilityWhy Verifiability is a vector for building trust in decentralized systems. It ensures that data is accurate, available, and reliable. Embedding this into a system from scratch is no small feat. For first-generation datachains, adding verifiability later often came at a steep cost: they were forced to compromise between performance and reliability, sacrificing one for the other. The problem with this is: Increased verifiability has typically led to slower data access, as verification demands heavy computational resources. And at times, data has even been lost, undermining the promise of “permanent” storage. While some chains might offer partial verification—such as verifying data between miners—they rarely extend verifiability across the entire stack. Extending verifiability to cover users, miners, and the data itself is far more complex. This gap leaves trust incomplete and undermines the system’s promise of reliability. Without true verifiability, permanence is, at best, an optimistic claim.Multi-Ledger Cycle All data on Irys goes through a multi-step process to establish reliability. The process begins in the Submit Ledger, a temporary holding area where incoming data is uploaded by users and verified by the protocol.Once data has been verified as uploaded in the Submit ledger, it’s “promoted” to the Publish Ledger, where it gains permanent status. This promotion comes with a Ingress proofs—a certification that the data was accurately uploaded and that a responsible party is accountable for its storage. This process confirms both the reliability of the data and its accessibility across the network.The Role of Matrix Packaging Matrix Packaging serves as the protocol’s mechanism for verifying that each miner contributes unique and provable storage capacity to the network. By embedding unique cryptographic properties into each partition, Matrix Packaging creates economic incentives for miners to store unique copies of data rather than attempting to recompute them on demand. This approach achieves two key outcomes: Economic Viability: Matrix Packaging ensures that storing unique copies of data is economical—and provable—for miners to maintain their storage commitments. Trust Through Validation: The process actively validates that miners are maintaining unique, intact copies of their assigned data. This discourages adversarial behaviors such as duplication or neglect, reinforcing trust across the network. Matrix Packaging bridges miner incentives and network reliability, creating a system where data storage is both efficient and provable—enabling scalable and actionable verifiability.Enabling Programmable Data Verifiability is central to Irys’s ability to support programmable data across applications. For data to function reliably in a decentralized ecosystem, it must come with provable guarantees of its origin, availability, and integrity. Irys achieves these guarantees through a multi-step process:Proof of UploadWhen new data is uploaded to the network or shared between miners, each miner generates a cryptographic proof of ingress. These proofs serve as verifiable records, ensuring data has been accurately uploaded, logged, and replicated.Each ingress proof includes:A Merkle Root that establishes the data’s inclusion in the Submit Ledger, cryptographically linking it to the network's storage framework.Metadata that specifies the miner responsible, the partition storing the data, and the time of submission, creating an immutable chain of accountability. Data AvailabilityMiners storing data are subject to periodic, randomized sampling challenges. Each challenge requires miners to produce:A valid hash of specific data ranges, verifying that the data remains intact.A timestamped response, demonstrating timely access and proving active maintenance.This process ensures that miners are continually validating the availability of their stored partitions, preventing data loss. Embedded PropertiesOnce data transitions to the Publish Ledger, it is equipped with embedded cryptographic proofs and programmable metadata. This metadata defines properties such as:Ownership rights (e.g., wallet addresses linked to the data).Access controls (e.g., permissions for specific contracts or users).Royalties or other monetization rules encoded for automatic enforcement.Data with embedded properties allow smart contracts to directly reference and enforce data rules without requiring external systems."
    }
  ]
}